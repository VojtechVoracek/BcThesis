% The documentation of the usage of CTUstyle -- the template for
% typessetting thesis by plain\TeX at CTU in Prague
% ---------------------------------------------------------------------
% Petr Olsak  Jan. 2013

% You can copy this file to your own file and do some changes.
% Then you can run:  pdfcsplain your-file
\input ctustyle2  % The template (in version 2) is included here.
%\input pdfuni    % Uncomment this if you need accented PDFoutlines
\input opmac-bib % Uncomment this for direct reading of .bib database files 
%\input my_references.bib



\worktype [B/EN]
\faculty {F3}
\department {Department of Cybernetics}
\title {Differential Evolution Crossover with Dependency Detection}
\titleCZ {Křížení pro diferenciální evoluci s detekcí závislostí}
\author {Vojtěch Voráček}
\date {March 2021}

\pagetwo    {}  % The text printed on the page 2 at the bottom.

\abstractEN {
   This document shows and tests an usage of the plain\TeX{} officially
   (may be) recommended design style {\ssr CTUstyle} for bachelor (Bsc.), master
   (Ing.), or doctoral (Ph.D.) theses at the Czech Technical University in
   Prague. The template defines all thesis mandatory structural elements and
   typesets their content to fulfil the university formal rules.

   This is version 2 of this template which implements the Technika font
   recommended by CTU graphics identity reference since 2016.
}
\abstractCZ {
    Abstrakt stručně a přesně
    reprezentuje obsah práce, shrnuje cíl, metody, výsledky a závěry. 
}           % If your language is Slovak use \abstractSK instead \abstractCZ

\keywordsEN {%
   document design template; bachelor, master, Ph.D. thesis; \TeX{}.
}
\keywordsCZ {%
    Klíčová slova jsou odborné termíny vyjadřující obsah práce. 
}
\thanks {           % Use main language here
   Chtěl bych poděkovat své manželce Ludmile za podporu nejen finanční.
   Díky tomu mohu na svém pracovišti dělat, co mě baví, a nejsem stresován 
   výplatní páskou.
}
\declaration {      % Use main language here
   Prohlašuji, že jsem předloženou práci vypracoval
   samostatně a že jsem uvedl veškeré použité informační zdroje v~souladu
   s~Metodickým pokynem o~dodržování etických principů při přípravě
   vysokoškolských závěrečných prací.

   V Praze dne 13. 13. 2013 % !!! Attention, you have to change this item.
   \signature % makes dots
}

%%%%% <--   % The place for your own macros is here.

%\draft     % Uncomment this if the version of your document is working only.
%\linespacing=1.7  % uncomment this if you need more spaces between lines
                   % Warning: this works only when \draft is activated!
%\savetoner        % Turns off the lightBlue backround of tables and
                   % verbatims, only for \draft version.
%\blackwhite       % Use this if you need really Black+White thesis.
%\onesideprinting  % Use this if you really don't use duplex printing. 

\makefront  % Mandatory command. Makes title page, acknowledgment, contents etc.


\chap Introduction

\sec Motivation

%Tady napisu, ze plno existuje rada situaci, kdy musime optimalizovat black box.
%K tomuto se hodi evolucni algoritmy, jednim z nejlepsich v real-value domene je DE.
%DE ma nevyhodu, ze nedokaze rozlisit zavislosti mezi castmi promennych a tedy nepracuje
%efektivne. Cilem je adaptovat standrardni DE, aby dokazala rozeznat zavislosti a
%pristusobit to, jakym zpusobem pracuje tomu, jak je to zavisle.

Striving for the best solution of a certain problem is an important part of many fields
of human interest. The process of finding the best solution according to some
criteria is called optimization. Optimization in mathematical notation:

In the real world, there are a large number of
engineering optimization problems whose input-output relationships are noisy and
indistinct, so it cannot be assumed anything about the optimized function but it's
possible to observe its outputs on given inputs. In these cases, the function is 
called a black box function and an optimization as a black box optimization.

Due to these limited capabilities, all black box optimization algorithms are
allowed to perform just these three steps:

\begitems
*Create a candidate solution
*Check if a candidate is feasible or not
*Evaluate its fitness by using the objective function
\enditems

From the mid-1950s, a new family of optimization algorithms called Evolutionary
algorithms has started to be developed.~\cite[Friedberg1958ALM,Friedberg1959ALM]
Evolutionary algorithms have proven to be very effective while optimizing black
box functions.~\cite[comparison] Among evolutionary algorithms, \em Differential
Evolution \em (DE) has achieved excellent results on real-valued black box functions.~\cite[DE].

However, there exists a class of functions containing dependent solution components
and the recognition of those components may be a crucial task which could lead to
significantly enhanced performance. Nevertheless, DE does not provide any tool capable of
recognizing the dependent components of a solution. Thus it can be seen that this particular
class of functions is the weakness of DE.

This work aims to find a way how to find dependencies between parts of solutions and
how to represent a dependency structure. It would lead to the proposal of a new crossover
operator for DE well suited for functions with dependent solution components. This new 
operator should partially eliminate the above-mentioned weakness of DE.



\chap Evolutionary algorithms

This chapter is mainly based on these references:~\cite[IntoEA, wong2015evolutionary, Luke2009]

Evolutionary algorithms (EAs) is a set of stochastic metaheuristic optimization algorithms
inspired by Darvin's theory of evolution by natural selection.~\cite[Darwin] The theory
describes the process of development of organisms over time as a result of changes
in heritable traits. Changes which allow an organism to better adapt to its environment
will help it survive and reproduce more offspring. This phenomenon is commonly
called as “Survival of the fittest” first used by Herbert Spencer.~\cite[Spencer]

In analogy, EA maintains a “population” of potential solutions (\em individuals\em) for the
given problem. Population is iteratively evolved by encouraging the reproduction of
fitter individuals. The fitness is usually the value of the objective function in the
optimization problem being solved. New candidate solutions are created either by
combining existing individuals (crossover) or by modification of an individual (mutation).
The algorithm runs until a candidate solution with sufficient quality is found
or a user-defined computational limit is reached.


\sec Components of evolutionary algorithms

In this section, certain parts of evolutionary algorithms are discussed in detail.
In general, EAs can be divided into various components, procedures, or operators,
which are:

\begitems
*representation of individuals
*objective function
*population
*parent selection
*crossover operator
*mutation operator
*replacement strategy
\enditems

To define a particular EA, it is necessary to specify these components. In addition,
the initialization procedure and the termination condition must be defined to obtain working
algorithm.

\secc Representation of individuals

Each individual is encoded in so called \em chromosomes\em. Representation of chromosome is
called \em genotype \em. While \em phenotype \em refers to the interpretation of the genotype,
in other words, how the objective function treats the genotype. The Representation also involves
a genotype-phenotype mapping. For instance, given an optimization problem on integers, if one
decide to represent them by their binary code, then $20$ would be seen as a phenotype 
and $10100$ as a genotype representing it.

\bigskip

\medskip
\picw=15.3cm \cinspic g-pmapping.png
\bigskip
\caption/f Examples of genotype-phenotype mapping
(a) Integere representation
(b) Protein structure representation on a lattice model
(c) Tree representation for a mathematical expression~\cite[wong2015evolutionary]
\medskip

\secc Objective function

The role of the objective function, is to represent the requirement to adapt to.
Objective function defines how quality individual is with respect to the problem
in consideration. Technically, it is a function which takes an individual as an input
and produces a the measure of quality of a given individual as an output. The measure of
quality is called \em fitness \em and the objective function is called \em fitness
function\em.

To remain with the above-mentioned example, the problem was to minimise $x^2$ on
integers. The fitness of the individual represented by the genotype $10100$ would be
defined as a square of its corresponding phenotype: $20^2 = 400$

\secc Population

Population in a evolutionary algorithm means a set of individuals. Population can be
specified only by setting the population size, in other words, how many individuals
are in population. This parameter is usually specified by user.

\secc Parent selection

During each \em generation \em (one iteration of algorithm), a certain part of population
is selected to breed offspring. 
The choice is made similarly to natural selection, in other words, fitter individuals
are preferred, nevertheless, low quality individuals are given a small, but positive change
to be selected. Otherwise, the EA could become too greedy and get stuck in the local optimum.
Parent selection along with the replacement strategy pushes quality improvements.
Parent selection as well as other EA procedures are usually stochastic.

Individuals selected by parent selection are called \em parents\em.

\secc Crossover operator

\em Crossover \em is a genetic operator used to combine typically two parents to
generate new offsprings. The idea behind crossover is that by mating two
individuals with different but desirable features, it is possible to produce offsprings
which combines both of those features. Similarly to other genetic operators, crossover is stochastic.

\medskip
\picw=15.3cm \cinspic crossover.png
\medskip
\caption/f Example of One-point crossover (part of chromosome right to the Crossover point
are swapped between two parents chromosomes)~\cite[crossoverpic]
\medskip


\secc Mutation operator

\em Mutation \em is an unary genetic operator which changes parts of the chromosome of an
individual, typically randomly. In mutation, the mutated individual may change entirely from
the original individual. Mutation is used to maintain and introduce diversity in the
genetic population.

\medskip
\picw=8cm \cinspic mutation.png
\medskip
\caption/f Example of mutation~\cite[mutationpic]
\medskip

\secc Replacement strategy

\em Replacement strategy \em defines which individuals survive and become members of
subsequent generation. Typically, the decision is based on the quality of individuals,
prefering those with higher fitness. The replacement strategy is similar to parent
selection, as both are responsible for promoting quality improvement. However,
parent selection is usually stochastic while the replacement strategy is often
deterministic.


\secc Initialization

It generates a defined number of individuals of the given representation, thereby
creating the initial population. \em Initialization \em is often done randomly
due to lack of knowledge when optimizing black box functions.


\secc Termination condition

The algorithm runs until the \em termination condition \em has been reached. If we
know the optimum of the optimized problem, then reaching the optimum (with a given
precision $\epsilon \geq  0$) is a natural termination condition. However, since EAs
are stochastic, there is usually no guarantee to reach an optimum and the condition
would be never satisfied. Therefore, this condition is extended to a condition which
certainly stops the algorithm, such as the limited number of fitness function calls.


\sec General scheme

%By merging all above-mentioned components, the evolutionary algorithm is formed.
%It this section
%irstly, an initial population is generated by initialization procedure.
In the previous section, the main parts of an EA were introduced individually.
By merging all above-mentioned components, the evolutionary algorithm is formed.
This section describes the way an EA works as a whole.
\bigskip

%\medskip
\picw=14cm \cinspic EApseudocode.jpg
\medskip
\caption/f General scheme of an evolutionary algorithm
%\medskip

\bigskip

Firstly, an initial population is generated by an initialization procedure.
The population is subsequently evaluated by a fitness function. Then starts
a generational process.

The generational process is repeated until a terminal
condition is not satisfied. Generational process starts by parent selection, usually
based on a fitness, some individuals are chosen to seed the new generation. The
chosen individuals are combined by a crossover operator to produce offsprings, which
are then modified by the mutation operator. Offspring are then evaluated by a fitness
function and the generational process ends by creating a new population. Creating a new
population is performed with respect to the replacement strategy that selects some newly
created offsprings to replace some members of the old population.

The algorithm returns the best individual found so far, eventually some statistics concerning
the run of algorithm.

\label[s23] \sec Differential evolution

This chapter is mainly based on these references:~\cite[DE, Luke2009]

Differential evolution was introduced by Storn and Price~\cite[DE] as an efficient
evolutionary algorithm initially designed for multidimensional real-valued spaces.

DE utilizes a population of real vectors. The initial population is chosen randomly.
After initialization, for each member $\vec{x}_i$ of a population $P$ is generated a
so called \em mutatant vector\em. A mutatant vector is generated by adding the
weighted difference between two individuals ($\vec{x}_{r_2}$, $\vec{x}_{r_3}$) to a third individual
($\vec{x}_{r_1}$). These three individuals are mutually exlusive. The mutant vector is then
crossed over with $\vec{x}_i$ 
The offspring $\vec{o}_i$ is then created by crossing over the mutatnt vector with $\vec{x}_i$.

Note that a size of mutatant vector is largely based on the actual variance in the
population. The mutant vector will make major changes if the population is spread, on
the other hand mutant vecotr will be small if the population is condensed in a
particular region. Thus DE belongs to the family of adaptive mutation algorithms.

Lastly, newly created offspring is compared to his parent using the greedy criteria.
If the offspring is better, it replace its parent in the population.

To put it more formally, standard DE is defined by specifying of following components of EA:


\secc Representation

Individuals are represented by real-valued vectors:
$$
\vec{x_i} = \{x_{i,0}, x_{i,1}, ..., x_{i,D-1}\},
\forall{j}: x_{i,j} \in{\bbchar{R}},
$$
\noindent where \em i \em represents the index of the individual in the population \em P \em
and \em D \em stands for dimension of the optimized function. Population is represented as
following:
$$
P = \{\vec{x}_0, \vec{x}_0, ..., \vec{x}_{NP-1}\},NP \geq 4,
$$
\noindent where \em NP \em is the size of population.


\secc Mutation

For each individual in the population $\vec{x}_i, i = 0, 1, ..., NP-1$, DE generates mutant
vector $\vec{m}_i$ as following:
$$
\vec{m}_i = \vec{x}_{r_1} + F*(\vec{x}_{r_2} - \vec{x}_{r_3})
$$
%\medskip
%\centerline{$\vec{m}_i = \vec{x}_{r_1} + F*(\vec{x}_{r_2} - \vec{x}_{r_3})$,}
%\medskip
\noindent with random, mutually exclusive indexes $r_1, r_2, r_3 \in\{0, 1, ..., NP-1\}$,
which are also chosen to be different from the running index \em i\em. $F$, called 
\em differential weight\em, is a constant factor $\in [0, 2]$, representing the
amplification of the random deviation $(\vec{x}_{r_2} - \vec{x}_{r_3})$. 

\secc Crossover

After mutation the mutant vector $\vec{m}_i$ undergoes a crossover with the its relevant
individual $\vec{x}_i$ to generate the offspring $\vec{o}_i$. Standard DE us binomial
crossover, where offspring is generated as following:
$$
f(x) = \cases{ -1 & for $x\ge 0$,\cr
0 & otherwise.} \eqmark
$$
%\medskip
%\centerline{$\vec{o}_i = \vec{x}_{r_1} + F*(\vec{x}_{r_2} - \vec{x}_{r_3})$......,}
%\medskip
\noindent where: \em description of symbols ....\em $\vec{x}_i$ is the parent of $\vec{o}_i$.
Therefore, it can be seen that each individual from the population generates offspring. In
other words, the parent selection chooses all individuals from the population.

The probability of crossover is signed as $CR$.


\secc Replacement strategy

To decide which individuals become members of subsequent generation, DE compares offspring
$\vec{o}_i$ to its relevant parent $\vec{x}_i$ using the greedy criteria. Thus, if $\vec{o}_i$
is better than $\vec{x}_i$, the offspring $\vec{o}_i$ will replace the parent $\vec{x}_i$ and
enter the population of the next generation. To put it more formally, new population is determined
as follows:

$$
P = \{\vec{p}_i |  \vec{p}_i = argmax(\vec{x}_i, \vec{o}_i); i = 0,1,...,NP-1\}
$$

%\medskip
%\centerline{$P = \{\vec{p}_i |  \vec{p}_i = argmax(\vec{x}_i, \vec{o}_i); i = 1,2,...,NP\}$,}
%\medskip


\bigskip

%\medskip
\picw=14cm \cinspic DEpseudocode.jpg
\medskip
\caption/f General scheme of the differential evolution
%\medskip

\bigskip

%\medskip
\picw=14cm \cinspic provisional.jpg
\medskip
\caption/f DE recombination
%\medskip

\bigskip



\label[ch3] \chap Linkage information modeling

It is worth nothing, that DE, as was described in previous chapter, uses random, uniform
crossover. The crossover has no assumptions about the structure of optimized function,
specially DE do not take possible dependencies between specific parts of solution into account.

However, there exists a whole class of problems with dependent solution components. De
using uniform crossover not only take posible dependencies into consideration, but even
very often disrupts linkage between strongly connected components. Therefore it can be seen
that mentioned class is a significant weakness of standard DE.

The aim of this work is to propose new crossover operator capable of finding dependencies
and taking them into account when generating new offspring. This chapter proposes two
possible representations of dependency structure and how to adapt crossover operator.

\sec Family Of Subsets

Both representations od dependency structure are based on the \em Family Of Subsets \em
(FOS).~\cite[FOS] FOS is a way how to model linkage information that describe presumed
dependencies between variables. FOS $\cal F = \{$$\cal F$$_1, $ $\cal F$$_2$$, ...\}$ 
represents a subset of powerset $\cal{P(I)}$ of $\cal{I}$, where $\cal{I}$$ =
\{1, 2, ..., d-1\}$ stands fos a set of indices and \em d \em is a number of problem
variables (dimension of the fitness function). Each block $\cal F$$_j \in$ $\cal F$
contains the indices of those variables that are considered dependent. The block $\cal F$$_j$
divides the set of all variables into two mutually exclusive subsets of variables $\cal F$$_j$ and
$\cal F$ $\setminus$ $\cal F$$_j$. Variable within those subsets are crossed over together.~\cite[FOS]

To put it more formally, within crossover for each individual $\vec{x}_i$ each block
$\cal F$$_j$ is iteratively considered in random order (crossover probability CR $= 1$).
For each block $\cal F$$_j$ is randomly generated new mutant vector $\vec{m}_i$ in the
same way as standard mutation. If the mutants values for variables contained in $\cal F$$_j$
are different from those in parent $\vec{x}_i$, then these value are overwritten in the
parent $\vec{x}_i$, this produces $\vec{x}_{i,new}$ which is then evaluated by the fitness
function. New individual $\vec{x}_{i, new}$ is only accented if it has better or equal
fitness value than the original $\vec{x}_i$. How the DE changes is captured in the
figure~\ref[DEFOSpseudocode].

%\bigskip

%\medskip
%\picw=14cm \cinspic DEFOSpseudocode.jpg
%\medskip
%\caption/f Pseudocode of DE with adjusted crossover when FOS is known
%\medskip

%\bigskip


\sec Linkage tree

There exist many FOS structures and any of them can be used to model linkage structure,
however this work focus on two of them. First of them is \em linkage tree \em (LT-FOS).

‘‘\em The Linkage Tree is the hierarchical cluster tree of the problem variables using
an agglomerative hierarchical clustering algorithm with a distance measure $\cal M$.
The distance measure $\cal M$$(X_1, X_2)$ measures the degree of dependency between
two sets of variables $X_1$ and $X_2$.\em’’~\cite[LT]

There exist more potential distance measures $\cal M$$(X_1, X_2)$, however, in this work,
two distance measures are used. They are described in detail in following chapter~\ref[ch4].

The linkage tree is a tree with $D$ leaf nodes and $D-1$ inner nodes, where $D$ is number
of problem variables. Each node of the LT-FOS represents certain block of variables $\cal F$$_j$.
The key property of the LT-FOS is that each $\cal F$$_j$ which containts more than one variable
is the union of two other sets $\cal F$$_k$, $\cal F$$_l \in $$\cal F$, where $j \neq k \neq l$
(transitively). To put it more formally, for any subset $\cal F$$_i$, where $|\cal F$$_j| > 1$,
there exist subsets $\cal F$$_k, \cal F$$_l$ for which the following applies:

\begitems
\style N
*$\cal F$$_k, \cal F$$_l \neq \emptyset$
*$\cal F$$_k \cap \cal F$$_l = \emptyset$
*$\cal F$$_k \cup \cal F$$_l$ = $\cal F$$_j$
\enditems

The hierarchical clustering procedure starts by assigning each problem variable to a separate
block in random order. The procedu proccedes bottom-up, therefore the tree is initialized with
these univariete blocks as leaves. In each step new node is created by merging two nodes of the
tree which were determined, by given distance measure $\cal M$, as the most dependent. It is
important to mention that each node can be merged only once. The process of merging stops
when no more merges are possible to put it another way, root node has been created.
Due to the way the procedure works, root node has to be a set of all problem variables.
The tree itself contains multiple levels of dependencies. From univariate level at a height of
zero to complete dependency between all variables at a depth of zero.~\cite[LT]

\medskip
\picw=10cm \cinspic LT.png
\medskip
\caption/f Example Linkage tree~\cite[LTpic]
\medskip


The \em DE using the LT FOS structure \em (LT-FOS DE) build the LT-FOS in every generation. 
Once the tree is built, LT-FOS DE traverses the tree in the opposite order of the merging.

\sec Marginal product

Second introduced FOS structure is \em marginal product \em (MP-FOS)~\cite[MP]. The MP-FOS is
defined as set $\cal F$, where for each $\cal F$$_k, \cal F$$_l \in \cal F$ holds that
$\cal F$$_k \cap \cal F$$_l = \emptyset$. When all variables are independent, MP-FOS is called
univariate FOS and $\cal F$$ = \{\{0\}, \{1\}, ... , \{D-1\}\}$, where $D$ is number of problem
variables. On the contrary, when all variables are considered dependent, MP-FOS is called compact
FOS.

Before introduction of the \em MP-FOS building procedure \em it is necessary to define
\em strength of block \em $\cal S_{M}$$(\cal F$$_j)$ which determines dependency rate
within certain block $\cal F$$_j$ according to given distance measure $\cal M$. The strength of
block is defined as following:

$$
{\cal S_M}({\cal F}_i) = \cases{ {C \over D-1} \sum_{v \in {\cal I}} {\cal M}({\cal F}_i,
\{v\}) & if $|{\cal F}_i| = 1$,\cr
{1 \over |{\cal F}_i| (|{\cal F}_i|-1)} \sum_{u \in {\cal F}_i} \sum_{v \in {\cal F}_i}
{\cal M}(\{u\}, \{v\}) & otherwise,} \eqmark
$$


\noindent where $C \geq 0$ is user selected factor defining the degree of strength of 
univariete blocks.

The MP-FOS building procedures starts by initializing MP-FOS $\cal F$ as univariete FOS and by
assigning the strength of block to each block. In each step new block $\cal F$$_n$ is created
by merging two blocks ${\cal F}_a, {\cal F}_b \in \cal F$, which are determined, by given
distance measure $\cal M$, as the most dependent. Then, $\cal F$$_n$ is assigned its strength
of block. If newly created block meets the following conditions:

\begitems
\style N
*${\cal S_M}({\cal F}_n) \geq \theta_1, \theta_1 \in{\bbchar{R}}$
*${\cal S_M}({\cal F}_n) \geq K max({\cal S_M}({\cal F}_a), {\cal S_M}({\cal F}_b))$,
*$|{\cal F}_n| \leq \theta_2, \theta_2 \in{\bbchar{N}}$,
\enditems

\noindent where thresholds $\theta_1 > 0$, $\theta_2 \in [1, D]$ and  factor $K \in (0,1]$ are defined by user.
Then $\cal F$$_n$ is inserted to the FOS $\cal F$ and $\cal F$$_a, \cal F$$_b$ are 
removed from $\cal F$. The procedure runs until a newly created block $\cal F$$_n$ has not
met mentioned conditions or until MP-FOS has became the compact FOS.

The \em DE using the MP FOS structure \em (MP-FOS DE) build the MP-FOS in every generation.
After building the MP-FOS, MP-FOS DE traverses FOS in the opposite order of the merging, in
other words, from the last one added to FOS to the first one.


\medskip
\label[DEFOSpseudocode]
\picw=14cm \cinspic DEFOSpseudocode.jpg
\medskip
\caption/f provisional pseudocode
\medskip

\label[ch4] \chap Identification of the linkage structure

In previous chapter two possible representations of dependency structure were introduced.
In order to represent the dependency structure, it is necessary to determine the degree
of dependence between each pair of variables and furthermore between each pair of sets of
variables. The tool used to measure the degree is called the distance measure and is
denoted as $\cal M$.

Formally, $\cal M$ is a function that takes two sets of variables as input and produces a
real, positive number as output. $\cal M$ is defined as follows~\cite[LT]:

$$
{\cal M}(X_i, X_j) = {1 \over |X_i| |X_j|} \sum_{u \in X_i} \sum_{v \in X_j}
p_{u, v} \eqmark
$$

\noindent where $X_i$ and $X_j$ are sets of variables and $p_{u, v}$ is element of the
\em dependency matrix \em $\cal P$ at position $u,v$.

The dependency matrix 

$$
%{\cal N} = \pmatrix{ a & b & \dot \cr c & d & \dot}
{\cal P} = \pmatrix{p_{0,0} & p_{0,1} & \dots & \dots & p_{0, D-1} \cr 
p_{1,0} & p_{1,1} & & & \vdots \cr
\vdots & & \ddots &  & \vdots \cr
\vdots & &  & \ddots & \vdots \cr
p_{D-1, 0} & \dots & \dots & \dots & p_{D-1, D-1}} \in {\bbchar R}^{D \times D}
$$

\noindent is a symetric and positive semi-definite matrix.
The dependency matrix gives the dependency between each pair of variables specifically,
the element $p_{i, j}$ denotes he pairwise dependency strength between i-th and j-th
problem variables. Consequently $\cal P$ contains zeros on diagonal i.e. $\forall i =
0, 1, ..., D-1 : p_{i, i} = 0$.

There are several methods how to contruct the dependency matrix $\cal P$ nevertheless,
this work focus only on two of them.

\sec Fitness-based method

The first method called \em non-linearity check \em (NC) is to define whether two
variables interact is directly based on fitness values. The method works under
the assumption that non-linear interactions may exist only between dependent
variables. Specially, it classify a pair of variables either separable or non-separable
by comparing the difference in overall fitness while making the exact same change for
a certain pair of chromosome of given individual $x_{i, j}$ for different values of
$x_{i, k}, k \neq j$.~\cite[LINC, LIMD] Nevertheless, checking only one individual
is not convincing enough, because there may exist linearity between a dependent pair
of variables in some context, therefore more individuals must be checked. In this work,
$m$ best individuals from the population are checked, where $m = max\{2, {3 \over 20}NP\}$.
$C$ denotes the set of indices of $m$ best individuals in population.

For each of chosen individuals $\vec{x}_i, i \in C$ and for each pair of variables $j$, $k$
a pairwise dependency $d_{i,j,k}$ is calculated. The overall pairwise dependency between
those variables is determined by aggregating those values as following:

$$
p_{j, k} = {1 \over m} \sum_{i \in C} d_{i,j,k}.
$$

In order to calculate $d_{i,j,k}$, four individuals are picked by combining all possible
points that can be created by picking two different values for each $x_{i,j}$ and
$x_{i,k}$.~\cite[MAIN] The absolute value of differences in overall fitness value
for those point are used to calculate the potential dependence between \em j-th \em and
\em k-th \em variables by determining whether the adjustment to $x_{i,k}$ affect the change
in fitness caused by modification to $x_{i,j}$. Define:

$$
\Delta_{i, j} = |(f(\vec{x}_i) | x_{i, j} = a_j, x_{i, k} = a_k) - (f(\vec{x}_{i}) |
x_{i, j} = a_j + b_j, x_{i, k} = a_k)|,
$$
$$
\Delta_{i, j,k} = |(f(\vec{x}_i) | x_{i, j} = a_j, x_{i, }k = a_k + b_k) -
(f(\vec{x}_i) | x_{i, j} = a_j + b_j, x_{i, k} = a_k + b_k)|, 
$$

\noindent where $f$ denotes fitness function, $a_j, a_k, b_j, b_k$ can be any real value,
such that for every variable $j, a_{j}$ and $a_{j} + b_{j}$ remains within the bound
for $x_{i,j}$ inside the current population, to put it more formally:

$$
\forall j :\max_{\vec{x}_i \in P}(x_{i,j}) \geq a_j \geq \min_{\vec{x}_i \in P}(x_{i,j}),
$$

$$
\forall j :\max_{\vec{x}_i \in P}(x_{i,j}) \geq a_j+b_j \geq \min_{\vec{x}_i \in P}(x_{i,j}),
$$

\noindent nevertheless, in this work are used values that have been empirically found
for~\cite[MAIN], which are

$$
a_j = \min_{\vec{x}_i \in P}(x_{i, j}) + (\max_{\vec{x}_i \in P}(x_{i, j}) -
\min_{\vec{x}_i \in P}(x_{i, j})) * 0.35,
$$

$$
b_j = (\max_{\vec{x}_i \in P}(x_{i, j}) - \min_{\vec{x}_i \in P}(x_{i, j})) * 0.35.
$$

Finally, \em j-th \em and \em k-rh \em are said to dependent when $|\Delta_{i,j} - \Delta_{i, j,k}|
\geq 0$, the pairwise dependent $d_{i,j,k}$ is defined as:

$$
d_{i,j,k} = \cases{1 - {\Delta_{i,j,k} \over \Delta_{i,j}} & if $\Delta_{i,j} \geq \Delta_{i,j,k}$,
\cr 1 - {\Delta_{i,j} \over \Delta_{i,j, k}} & otherwise.} \eqmark
$$

\noindent note that $d_{i,j,k}$ as well as $p_{j,k}$ lie within $[0, 1)$ with $0$ indicating
independent variables.


\sec Distribution-based mathod
The second method to construct the dependency matrix $\cal P$ is called the \em maximal
information coefficient \em (MIC)~\cite[MIC]. There exists more methods used to identify
dependencies between a pair of variables based on the distribution of the
population~\cite[MP, MAIN], however MIC achieved better accurancy in comparison to other
methods.~\cite[MIC, MIC2]

MIC is based on the idea, that if a relationship between a pair of variables exists,
then it is posible to draw a grid on the scatterplot of the two variables that partitions
the data to encapsulate that relationship.

To calculate MIC, all possible grids up to maximal grid resolution are considered. Note
that maximal grid resolution depends on the sample size. For each pair of integers $(x, y)$
the largest possible mutual information (MI)~\cite[MI] achieveable by any x-by-y grid applied
to the data is computed. Those mutual information values are then normalized by the logarithm
of the minimum $x$ and $y$. Finally, MIC is defined as maximum of thos highest normalized
mutual information values.~\cite[MIC] Formally:

$$
MIC_{i,j} = \max_{(x,y) : x \leq B, y \leq B} \Bigg( \max_{g : G_{x, y}} \Big( {MI_{i,j}|_g
\over \log \min(x, y)} \Big)\Bigg),
$$

\noindent where $B$ is user-specified value defining maximal grid resolution, $G_{x,y}$ denotes
a set of all possible x-by-y grids and $MI_{i,j}|_g$ stands for mutual information of $i$-th and
$j$-th variables achieved by application of grid $g$.

As was mentioned above achieved good results in various comparisons, however a big limitation
of MIC is its high computational cost. Therefore several optimized algorithms for approximating
the MIC have been published.~\cite[MIC, TIC, GMIC]. In this work MICE \em minepy \em
implementation~\cite[MICE, MINEPY] is used.

In this wrok MICE is not calculated from the whole population, but only subset $C$ of all
individuals in population is considered. The dependency matrix $\cal P$ is then formally
calculated as following:


\centerline{$p_{i,j} = $ MICE$_{i,j}|_C$.}



\chap Experiments

In \ref[s23] section the standard differential evolution was introduced. It was also noted
that DE does not have any tool to recognize or model the linkage information between certain
parts of solution. In chapter \ref[ch3] two possible
representations of dependency structure were introduced assuming known pairwise dependencies
and in the chapter ~\ref[ch4] two ways to find pairwise dependencies and thereby build the dependency matrix
$\cal P$ were presented.

By combination of above it is possible to propose adjusted DE with dependency detection. The
adjusted version differs from original in two factors. Firstly, in every generation the
dependency matrix $\cal P$ and FOS structure based on it is built. Secondly, crossover is
modified to respect dependent blocks.

\medskip
\picw=14.7cm \cinspic DE_final.png
\bigskip
\caption/f Pseudocode of DE with dependency detection
\medskip

The main goal of experiments is to study performance of various types of DE with dependency
detection differing in creating the matrix $\cal P$, or in the building FOS $\cal F$. Compare
them between each other and with standard DE and other optimization algorithms.

\sec Setup

All experimental results described in this work measures the first time a global optimum was
hit, in other words, the number of fitness function calls needed to reach the global optimum
for the first time within the run. For each problem, each algorithm and each dimension 25
independent runs are performed. The performance is considered successful if at least 24 runs
converged to the global optimum or to a predefined sufficiently close approximation within
$300000 \cdot D$ calls of the fitness function. Toleration was set to $10^{-8}$.

The associate population size is the smallest possible size so that the algorithms performance
is considered successful. It is determined by starting from smallest possible population and
letting the algorithm runs 25 times. If the performance have not been successful, the population
size for the next trial will increase by $k$. This procudere is repeated until the successful
population size is found ot until population size reaches upper limit $T$. In the first case
optimal population size is searched for by performing bisection search between the current
poopulation size and the previous size. In the second case is considered unsuccessful for
certain problem and dimension.

All experimental result are arithmetically averaged over successful runs.



\sec Algorithms

\secc Differential evolution variants

Within the experiments seven types of differential evolution were compared. The original DE
as was introdued in~\ref[s23] section. (DE\_UNIFORM). Remaining six variants of DE are divided
into three pairs according to how they create the distance matrix $\cal P$. Within each pair,
one variant uses linkage tree FOS (LT) and second marginal product FOS (MP). The first pair
uses nonlinearity check to create $\cal P$ (DE\_LT\_NC and DE\_MP\_NC). The second pair take
advantage of maximal information coefficient (DE\_LT\_MIC and DE\_MP\_MIC). The third pair
are DE variants with full prior knowledge of pairwise dependencies, therefore they build
optimal $\cal P$, which is (0, 1)-matrix with zeros for independent pairs and ones for
dependent (DE\_LT+ and DE\_MP+).

\midinsert \clabel[DEvariants]{DEvariants}
\ctable{cccc}{
\hfil 
& Nonlinearity check & Max. inf. coeff. & Optimal \crl \tskip4pt
Linkage tree & DE\_LT\_NC & DE\_LT\_MIC & DE\_LT+ \cr
Marginal product & DE\_MP\_NC & DE\_MP\_MIC & DE\_MP+ \cr
}
\caption/t Overview of newly proposed variants of DE.
\endinsert

\noindent All above-mentioned types shares the following:

\begitems
*Initialization of individuals $\sim {\cal N}({\bf 0},100 \cdot {\bf I}_D)$, where $\cal N$ is
multivariate normal distribution, $\bf 0$ stands for the zero vector and ${\bf I}_D$ represents
$D \times D$ identity matrix.
*The diffrential weight $F = 0.7$
\enditems

\noindent Other parameters:

\begitems
*The crossover probability for DE\_UNIFORM: $CR = 0.9$
*The degree of strength of univariate blocks: $C = 2$
*Threshold $\theta_1$ defining the minimal strength of block to be accepted:

$$
\theta_1 = \cases{ 10^{-1} & for DE\_MP\_MIC,\cr
10^{-8} & otherwise.} 
$$
*Maximal size of block: $\theta_2 = 6$
*Maximum potential degree of strength of block reduction during merging

$$
K = \cases{ 0.8 & for DE\_MP+,\cr
0.4 & for DE\_MP\_NC,\cr
0.7 & for DE\_MP\_MIC.} 
$$

*Number of checked individuals within non-linearity check method: $m = \lceil0.15 \cdot NP\rceil$
*The subset used to calculate MICE $C = C_b \cup C_r$, where $C_b$ is set of $\lceil 0.3 \cdot
NP\rceil$ best individuals in population and $C_r$ is a set of $\lceil 0.1 \cdot NP\rceil$
randomly chosen individuals from the remaining.
*The maximal MICE grid resolution $B$ is set according to the following table (rounded to the
nearest integer in an upward direction):


\midinsert \clabel[Bset]{Bset}
\ctable{ll}{
\hfil 
Number of samples & B parameter\crl \tskip4pt
$|C| < 25$ & $ |C|^{0.85}$ \cr
$25 \leq |C| < 50$ & $|C|^{0.8}$ \cr
$50 \leq |C| < 250$ & $|C|^{0.75}$ \cr
$250 \leq |C| < 500$ & $|C|^{0.7}$ \cr
$500 \leq |C| < 1000$ & $|C|^{0.65}$ \cr
$1000 \leq |C| < 2500$ & $|C|^{0.60}$ \cr
$2500 \leq |C| < 5000$ & $|C|^{0.55}$ \cr
}
\caption/t The dependence of the cardinality of $C$ on the parameter $B$ taken
from~\cite[MICE].
\endinsert

*For the MICE parameter $c$ which determines how many more clumps
there will be than columns in every partition was set default value $15$~\cite[MICE]
\enditems


\noindent All above-mentioned values were found empirically unless otherwise stated.

\secc Other algorithms

Covariance matrix adaptation evolution strategy (CMA-ES) belongs to the class of
evolutionary algorithms. CMA-ES is considered state-of-the-art in evolutionary
computation and has very quickly become the standard tool for continuous
optimisation.~\cite[CMAES1, CMAES2, CMAES3]
In this work the Hanses's implementation of CMA-ES is used.~\cite[CMAESIMPLEMENTATION]

Last considered algorithm is Nelder-Mead simplex algorithm~\cite[FMIN], the optimization algorithm
which is not an evolutionary algorithm nevertheless, it uses only function values,
therefore may be used for blackbox optimization. The Scipy implementation called
FMIN is used~\cite[SCIPY].



\sec Problems

To study the impact of various types of linkage learning on the performance of DE and to
benchmark all above-mentioned algorithm, six optimization problems to minimize are considered.

Before the introduction of the problems, state the important property of functions, the
\em additive separability\em. Define additively separable function $F$ as:

$$
F(x_0, x_1, ..., x_{D-1}) = f_0(x_0) + f_1(x_1) + ... + f_{D-1}(x_{D-1}),
$$

\noindent where $f_0, f_1, ..., f_{D-1}$ are functions of one variable. It is crucial that
the optimum of D-dimensional additively separable function may be obtained by performing
D independent one-dimensional optimizations along each dimension, formally:

$$
\min_{[x_0, x_1, ..., x_{D-1}] \in{\bbchar{R}^D},} F(x_0, x_0, ..., x_{D-1}) = \min_{x_0 \in{\bbchar{R}}}
f_0(x_0) + \min_{x_1 \in{\bbchar{R}}} f_1(x_1) + ... + \min_{x_{D-1} \in{\bbchar{R}}} f_{D-1}
(x_{D-1})
$$

It can be seen that standard DE which optimize each dimension independently would be suitable
for optimizing additively separable functions because additively separable function are
exactly those function without dependencies between variables.


\secc Sphere

The first benchmark function is sphere funcion also known as De Jong F1~\cite[DEJONG]. It is presumable the easiest
continous domain optimization problem. It is convex, separable and has one local minimum.

Definition of the sphere function:
$$
f_{sphere}(\vec{x}) = \sum_{i=0}^{D-1}x_i^2
$$
Global minimum:
$$
f_{sphere}(\vec{x}_{min}) = 0
$$
$$
\vec{x}_{min} = [0, 0, ..., 0]
$$


\secc Levy

The second considered benchmark problem is Levy function~\cite[LEVY]. Like Sphere, it is separable
function with one local minimum nevertheless, Levy function is considered more difficult to
optimize.

The Levy function is defined as follows:
$$
f_{Levy}(\vec{x}) = \sin^2(\pi v_0) + \sum_{i=0}^{D-2}\Big[(v_i -1)^2 (1 + 10\sin^2(\pi v_i +1)
)\Big] + (v_{D-1} - 1)^2 (1 + sin^2(2\pi v_{D-1})), 
$$
\noindent where $v_i = 1 + {x_i -1 \over 4}$, for all $i = 0, 1, ..., D-1$.
\medskip
\noindent Global minimum:
$$
f_{Levy}(\vec{x}_{min}) = 0
$$
$$
\vec{x}_{min} = [1, 1, ..., 1]
$$

\secc Rastrigin

The Rastrigin function~\cite[RASTRIGIN, RASTRIGIN2] is the third benchamrk problem. Like the previous functions, this one
is also separable. It it difficult function to optimize, due to regular ‘‘noise'' it has many
regularly distributed local minimum. The Rastrigin function is defined as:
$$
f_{Rastrigin}(\vec{x}) = 10 \cdot D + \sum_{i=0}^{D-1}\Big [x_i^2 - 10\cos(2\pi x_i) \Big]
$$
Global minimum:
$$
f_{Rastrigin}(\vec{x}_{min}) = 0
$$
$$
\vec{x}_{min} = [0, 0, ..., 0]
$$

\secc Rosenbrock
The Rosenbrock function~\cite[ROSENBROCK], also known as Banana function is the first considered unseparable
function, because it has overlapping dependencies. Each pair of consecutive variables is
dependent. The Rocenbrock function contains narrow, parabolic valley, where the global
minimum is located. However, even though this valley is easy to find, convergence to the
minimum is difficult~\cite[HARDROSENBROCK]. The definition of Rosenbrock function is as follows:
$$
f_{Rosenbrock}(\vec{x}) = \sum_{i=0}^{D-2} \Big [100 (x_{i+1} - x_i^2)^2 + (1 - x_i)^2\Big]
$$
Global minimum:
$$
f_{Rosenbrock}(\vec{x}_{min}) = 0
$$
$$
\vec{x}_{min} = [1, 1, ..., 1]
$$

\secc SoREB

The Sum of Rotated Ellipsoid Blocks or abbreviated SoREB~\cite[MP] is defined as follows:
$$
f_{Ellipsoid}(\vec{x}) = \sum_{i=0}^{l-1} \Big [10^{{6i \over l-1}}x_i^2\Big]
$$
$$
f_{SoREB}(\vec{x}, k) = \sum_{i=0}^{D/k-1} \Big[f_{Ellipsoid}\big(R_\theta([x_{ki}, ..., x_{k(i+1)-1}])\big) \Big]
$$

\noindent Where $R_\theta$ defines the rotation of a vector around the origin by the angle of
$\theta$ and $k$ is size of block, defined by user. Rotated blocks of variables which enter to
$f_{ellipsoid}$ as an input creates strongly connected components. Variables within the block
have strong dependencies but are completely independent of any variables outside their block.
This feature is called block-separability.

Within comparison four types of the SoREB function differing in the size of blocks (2, 3, 4, 5)
were considered. The rotation of $\theta = 45^\circ$ was used.

\noindent Global minimum:
$$
f_{SoREB}(\vec{x}_{min}, k) = 0; k \in{\bbchar{N}}
$$
$$
\vec{x}_{min} = [0, 0, ..., 0]
$$



\secc OSoreb

The SoREB function conations only non-overlapping non-decomposable block of size $k$. In~\cite[MP]
the overlapping version of this problem was defined as OSoREB. In addition to the original
SoREB problem a SoREB blocks of length 2 for every pair of successive variables in belonging to
other original blocks are used. For OSoREB is used $k = 5$ and $\theta = 45^\circ$.
Definition of OSoREB:
$$
f_{OSoREB}(\vec{x}, k) = f_{SoREB}(\vec{x}, k) + \sum_{i=1}^{D/k-1} \Big [f_{Ellipsoid}\big(R_\theta([x_{ki-1}, x_{ki}])\big)\Big]
$$
Global minimum:
$$
f_{OSoREB}(\vec{x}_{min}, k) = 0; k \in{\bbchar{N}}
$$
$$
\vec{x}_{min} = [0, 0, ..., 0]
$$


\chap Results







%\chap Results

\bibchap
\usebib/c (simple) myreferences


\bye