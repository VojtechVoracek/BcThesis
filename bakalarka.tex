% The documentation of the usage of CTUstyle -- the template for
% typessetting thesis by plain\TeX at CTU in Prague
% ---------------------------------------------------------------------
% Petr Olsak  Jan. 2013

% You can copy this file to your own file and do some changes.
% Then you can run:  pdfcsplain your-file
\input ctustyle2  % The template (in version 2) is included here.
%\input pdfuni    % Uncomment this if you need accented PDFoutlines
\input opmac-bib % Uncomment this for direct reading of .bib database files 
%\input my_references.bib
\input glosdata


\worktype [B/EN]
\faculty {F3}
\department {Department of Cybernetics}
\title {Differential Evolution Crossover with Dependency Detection}
\titleCZ {Křížení pro diferenciální evoluci s detekcí závislostí}
\author {Vojtěch Voráček}
\date {May 2021}
\supervisor {Ing. Petr Pošík, Ph.D.}


\pagetwo    {
   \picw=18.3cm 
   \cinspic zadani.png
}  % The text printed on the page 2 at the bottom.


\abstractCZ {
    Diferenciální evoluce je považována za jeden z nejlepších evolučních algoritmů
    pro spojité black-box optimalizační problémy. Originální verze diferenciální evoluce
    použí náhodný uniformí operátor křížení, který nebere v potaz potencialní závislosti
    mezi částmi řešení a může tyto vazby narušovat.

    \medskip

    Cílem této práce je poskytnout nový operátor křížení pro diferenciální evoluci,
    který bude vhodnější pro třídu problémů obsahující závislé komponenty řešení.

    \medskip

    V této práci jsou prezentovány dvě možnosti, jak nalézt závislosti mezi proměnnými
    problému a dvě možnosti, jak modelovat strukturu vazeb. S užitím těhto metod byly
    navženy čtyři nové operátory křížení.

    \medskip

    Nově navržené algoritmy jsou vyhodnoceny na množině referenčních funkcí a jsou
    porovnány s dalšími optimalizačními algoritmy, včetně original diferenciální evoluce.

    \medskip

    Výsledky ukazují, že nově navžené algoritmy dosahují výrazně lepšího výkonu a
    škálovatelnosti než originální diferenciální evoluce ve smyslu potřebného počtu
    vyhodnocení účelové funkce k nalezení globálního optima. Něktére z nich podobné
    škálovatelnosti jako CMA-ES, jeden z nejmodernějších evolučních algoritmů.

    \medskip

}           % If your language is Slovak use \abstractSK instead \abstractCZ

\abstractEN {
   The differential evolution is considered one of the best evolutionary
   algorithms for continuous black-box optimization problems. The original version of
   differential evolution uses a random uniform crossover operator, which does not take
   possible dependencies between parts of the solution into account and may disrupt
   these linkages.

   \medskip
   This work aims to propose a new crossover operator for differential
   evolution more suitable for the class of problems containing dependent solution components.

   \medskip

   This work presents two options to find dependencies between problem variables
   and two possibilities to model the linkage structure. Finally, with the use of those
   methods, four new crossover operators are designed.

   \medskip

   Newly proposed algorithms are evaluated on a set of benchmark functions and compared
   with other optimization algorithms, including the original differential evolution.

   \medskip

   The results show that all newly proposed algorithms achieve significantly better performance
   and scalability than original differential evolution in terms of fitness function
   evaluations needed to find a global optimum. Some of them achieve comparable scalability
   to state-of-the-art evolutionary algorithm CMA-ES.

   \medskip
}


\keywordsEN {%
   Evolutionary algorithm, differential evolution, linkage tree, marginal product,
   non-linearity check, maximal information coefficient, linkage learning.
}
\keywordsCZ {%
    Evoluční algoritmus, diferenciální evoluce, vazebný strom, mezní produkt,
    kontrola nelinearity, maximální informační koeficient, učení se závislostí. 
}
\thanks {           % Use main language here
   First of all, I would like to express my gratitude to my supervisor Ing. Petr
   Pošík, Ph.D. for his guidance, his helpful comments, and his patience with me.
   \smallskip
   \rightline{Thank you!}
   \smallskip
   Many thanks also belong to my family, current and future, and all my friends
   for their support.
   \smallskip
   \rightline{Love you!}
}
\declaration {      % Use main language here
   I declare that the presented work was developed independently and that I have
   listed all sources of information used
   within it in accordance with the methodical instructions for observing the ethical
   principles in the preparation of university
   theses.
   \smallskip
   Prague, 20. May 2020 % !!! Attention, you have to change this item.
   \signature % makes dots
}

%%%%% <--   % The place for your own macros is here.

%\draft     % Uncomment this if the version of your document is working only.
%\linespacing=1.7  % uncomment this if you need more spaces between lines
                   % Warning: this works only when \draft is activated!
%\savetoner        % Turns off the lightBlue backround of tables and
                   % verbatims, only for \draft version.
%\blackwhite       % Use this if you need really Black+White thesis.
%\onesideprinting  % Use this if you really don't use duplex printing. 

\makefront  % Mandatory command. Makes title page, acknowledgment, contents etc.


\chap Introduction

\sec Motivation

%Tady napisu, ze plno existuje rada situaci, kdy musime optimalizovat black box.
%K tomuto se hodi evolucni algoritmy, jednim z nejlepsich v real-value domene je DE.
%DE ma nevyhodu, ze nedokaze rozlisit zavislosti mezi castmi promennych a tedy nepracuje
%efektivne. Cilem je adaptovat standrardni DE, aby dokazala rozeznat zavislosti a
%pristusobit to, jakym zpusobem pracuje tomu, jak je to zavisle.

Striving for the best solution to a particular problem is an essential part of many fields
of human interest. The process of finding the best solution according to some
criteria is called optimization.

In the real world, there are a large number of
engineering optimization problems whose input-output relationships are noisy and
indistinct, so it cannot be assumed anything about the optimized function. However, it is
possible to observe its outputs on given inputs. In these cases, the function is 
called a black box function and an optimization as a black box optimization.

Due to these limited capabilities, all black box optimization algorithms are
allowed to perform just these three steps:

\begitems
*Create a candidate solution
*Check if a candidate is feasible or not
*Evaluate its fitness by using the objective function
\enditems

From the mid-1950s, a new family of optimization algorithms called Evolutionary
algorithms has started to be developed.~\cite[Friedberg1958ALM,Friedberg1959ALM]
Evolutionary algorithms have proven to be very effective while optimizing black
box functions.~\cite[comparison] Among evolutionary algorithms, \em Differential
Evolution \em (DE) has achieved excellent results on real-valued black box functions.~\cite[DE].

However, there exists a class of functions containing dependent solution components
and the recognition of those components may be a crucial task that could lead to
significantly enhanced performance. Nevertheless, DE does not provide any tool capable of
recognizing the dependent components of a solution. Thus it can be seen that this particular
class of functions is the weakness of DE.

This work aims to find a way to find dependencies between parts of solutions and
how to represent a dependency structure. It would lead to the proposal of a new crossover
operator for DE well suited for functions with dependent solution components. This new 
operator should partially eliminate the weakness mentioned above of DE.



\chap Evolutionary algorithms

Evolutionary algorithms (EAs)~\cite[IntoEA, wong2015evolutionary, Luke2009] is a set
of stochastic metaheuristic optimization algorithms
inspired by Darvin's theory of evolution by natural selection~\cite[Darwin]. The theory
describes the process of developing organisms over time as a result of changes
in heritable traits. Changes that allow an organism to better adapt to its environment
will help it survive and reproduce more offspring. This phenomenon is commonly
called “\em Survival of the fittest\em”, first used by Herbert Spencer~\cite[Spencer].

In analogy to the natural environment, EA maintains a \em population \em of potential
solutions (\em individuals\em)
for the given problem. The population is iteratively evolved by encouraging the reproduction of
fitter individuals. The fitness is usually the value of the objective function in the
optimization problem being solved. New candidate solutions are created either by
combining existing individuals (crossover) or by modifying an individual (mutation).
The algorithm runs until a candidate solution with sufficient quality is found,
or a certain user-defined limit is reached.


\sec Components of evolutionary algorithms

In this section, certain parts of evolutionary algorithms are discussed in detail.
In general, EAs can be divided into various components, procedures, or operators,
which are:

\begitems
*representation of individuals
*objective function
*population
*parent selection
*crossover operator
*mutation operator
*replacement strategy
\enditems

To define a particular EA, it is necessary to specify these components. In addition,
the initialization procedure and the termination condition must be defined to obtain
a working algorithm.

\secc Representation of individuals

Each individual is encoded in so-called \em chromosomes\em. The representation of chromosomes is
called \em genotype \em. \em Phenotype \em refers to the interpretation of the genotype,
in other words, how the objective function treats the genotype. The Representation also involves
genotype-phenotype mapping. For instance, given an optimization problem on integers, if one
decides to represent them by their binary code, $20$ would be seen as a phenotype 
and $10100$ as a genotype representing it.

\secc Objective function

The role of the objective function is to represent the requirement to adapt to.
The objective function defines how quality an individual is with respect to the problem
in consideration. Technically, it is a function that takes an individual as input
and produces the measure of the quality of a given individual as an output. The measure of
quality is called \em fitness\em, and the objective function is called \em fitness
function\em.

To remain with the example mentioned above, if the problem was to minimize $x^2$ on
integers. The fitness of the individual represented by the genotype $10100$ would be
defined as a square of its corresponding phenotype: $20^2 = 400$

\secc Population

Population within an evolutionary algorithm means a set of individuals. A population can be
specified only by setting the population size. In other words, how many individuals
are in the population. This parameter is usually specified by the user.

\secc Parent selection

During each \em generation \em (one iteration of an algorithm), a specific part of the 
population is selected to breed offspring. 
The choice is made similar to natural selection. In other words, fitter individuals
are preferred. Nevertheless, low quality individuals are given a small but positive chance
to be selected. Otherwise, the EA could become too greedy and get stuck in the local optimum.
\em Parent selection\em, along with the replacement strategy, pushes quality improvements.
Parent selection, as well as other EA procedures, are usually stochastic.

Individuals selected by parent selection are called \em parents\em.

\secc Crossover operator

The \em crossover \em is a genetic operator used to combine typically two parents to
generate new offsprings. The idea behind the crossover is that by mating two
individuals with different but desirable features, it is possible to produce offsprings
that combine both of those features. Similar to other genetic operators, the crossover is
stochastic.

\secc Mutation operator

The \em mutation \em is a unary genetic operator that changes parts of an individual's
chromosome, typically randomly. In mutation, the mutated individual may change entirely from
the original individual. The mutation is used to maintain and introduce diversity in the
population.

\secc Replacement strategy

\em Replacement strategy \em defines which individuals survive and become members of the
subsequent generation. Typically, the decision is based on the quality of individuals,
preferring those with higher fitness. The replacement strategy is similar to parent
selection, as both are responsible for promoting quality improvement. However,
parent selection is usually stochastic, while the replacement strategy is often
deterministic.


\secc Initialization

The \em Initialization \em procedure generates a defined number of individuals of the
given representation, thereby creating the initial population. Initialization is
often done randomly due to a lack of knowledge when optimizing black box functions.


\secc Termination condition

The algorithm runs until the \em termination condition \em has been reached. If we
know the optimum of the optimized problem, then reaching the optimum (with a given
precision $\epsilon \geq  0$) is a natural termination condition. However, since EAs
are stochastic, there is usually no guarantee to reach an optimum, and the condition
would never be satisfied. Therefore, this condition is extended with the condition that
certainly stops the algorithm, such as the limited number of fitness function calls.


\sec General scheme

In the previous section, the main parts of an EA were introduced individually.
By merging all the above-mentioned components, the evolutionary algorithm is formed.
This section describes the way the EA works as a whole.

\midinsert \clabel[EAPSEUDO]{Evolutionary algorithm pseudocode}
\picw=14cm \cinspic EApseudocode.jpg
\medskip
\caption/f General scheme of an evolutionary algorithm
\endinsert

Firstly, an initial population is generated by an initialization procedure.
The fitness function subsequently evaluates the population. Then starts
a generational process.

The generational process is repeated until a terminal
condition is not satisfied. The generational process starts with parent selection, usually
based on fitness, some individuals are chosen to seed the new generation. The
chosen individuals are combined by a crossover operator to produce offsprings, which
are then modified by the mutation operator. A fitness function subsequently evaluates oﬀsprings,
and the generational process ends by creating a new population. Creating a new
population is done with respect to the replacement strategy that selects some newly
created offsprings to replace some members of the old population.

The algorithm returns the best individual found so far, eventually some statistics concerning
the run of the algorithm.

\label[s23] \sec Differential evolution


Differential evolution was introduced by Storn and Price~\cite[DE] as an efficient
evolutionary algorithm initially designed for multidimensional real-valued spaces.

DE~\cite[Luke2009] utilizes a population of real vectors. The initial population is chosen randomly.
After initialization, for each member $\vec{x}_i$ of a population $P$ is generated a
so-called \em mutant vector\em. The mutant vector is generated by adding the
weighted difference between two individuals ($\vec{x}_{r_2}$, $\vec{x}_{r_3}$) to a third individual
($\vec{x}_{r_1}$). These three individuals are mutually exclusive.
The offspring $\vec{o}_i$ is then created by crossing over the mutant vector with $\vec{x}_i$.

Note that the impact of the mutant vector is largely based on the actual variance in the
population. The mutant vector will make major changes if the population is spread. On
the other hand, the mutant vector will be small if the population is condensed in a
particular region. Thus DE belongs to the family of adaptive mutation algorithms.

Lastly, the newly created offspring is compared to his parent using the greedy criteria.
If the offspring is better than his parent, it replaces its parent in the population.

To put it more formally, standard DE is defined by specifying of following components of EA:


\secc Representation

Individuals are represented by real-valued vectors:
$$
\vec{x_i} = \{x_{i,0}, x_{i,1}, ..., x_{i,D-1}\},
\forall{j}: x_{i,j} \in{\bbchar{R}},
$$
\noindent where \em i \em represents the index of the individual in the population \em P \em
and \em D \em stands for the dimension of the optimized function. The population is
represented as follows:
$$
P = \{\vec{x}_0, \vec{x}_0, ..., \vec{x}_{NP-1}\},NP \geq 4,
$$
\noindent where \em NP \em is the size of population.


\secc Mutation

For each individual in the population $\vec{x}_i, i = 0, 1, ..., NP-1$, DE generates mutant
vector $\vec{m}_i$ as following:
$$
\vec{m}_i = \vec{x}_{r_1} + F \cdot (\vec{x}_{r_2} - \vec{x}_{r_3})
$$
\noindent with random, mutually exclusive indexes $r_1, r_2, r_3 \in\{0, 1, ..., NP-1\}$,
which are also chosen to be different from the running index \em i\em. $F$, called 
\em differential weight\em, is a constant factor $\in [0, 2]$, representing the
amplification of the random deviation $(\vec{x}_{r_2} - \vec{x}_{r_3})$. 

\secc Crossover

After the mutation, the mutant vector $\vec{m}_i$ undergoes a crossover with its relevant
individual $\vec{x}_i$ to generate the offspring $\vec{o}_i$. Standard DE us binomial
crossover, where offspring is generated as follows:
$$
\vec{o}_i = \cases{ \vec{m}_i & if $i = R \lor rand(0,1) < CR$,\cr
\vec{x}_i & otherwise.} \eqmark
$$
\noindent where: $R \in [0, D]$ is a random integer, $rand(0,1)$ represents a random number
between zero and one, and $CR$ denotes the probability of crossover. 
Since $\vec{x}_i$ is the parent of $\vec{o}_i$, it can be seen that each individual from the population generates offspring. In
other words, the parent selection chooses all individuals from the population.


\secc Replacement strategy

To decide which individuals become members of the subsequent generation, DE compares offspring
$\vec{o}_i$ to its relevant parent $\vec{x}_i$ using the greedy criteria. Thus, if $\vec{o}_i$
is better than $\vec{x}_i$, the offspring $\vec{o}_i$ will replace the parent $\vec{x}_i$ and
enter the population of the next generation. Formally, the new population is determined
as follows:

$$
P = \{\vec{p}_i |  \vec{p}_i = argmax(\vec{x}_i, \vec{o}_i); i = 0,1,...,NP-1\}
$$

\midinsert \clabel[DEPSEUOD]{Differential evolution pseudocode}
\picw=14cm \cinspic DEpseudocode.jpg
\medskip
\caption/f General scheme of the differential evolution
\endinsert

\label[ch3] \chap Linkage information modeling

It is worth noting that DE, as was described in the previous chapter, uses random, uniform
crossover. The crossover has no assumptions about the structure of the optimized function.
Specially DE does not take possible dependencies between specific parts of the solution
into account.

However, there exists a whole class of problems with dependent solution components. DE
using uniform crossover does not take possible dependencies into consideration and
often disrupts linkage between strongly connected components.

The aim of this work is to propose a new crossover operator capable of finding dependencies
and taking them into account when generating new offsprings. This chapter proposes two
possible representations of dependency structure and introduces an adapted crossover operator.

\sec Family Of Subsets

Both representations of dependency structure are based on the \em Family Of Subsets \em
(FOS)~\cite[FOS]. FOS is a way how to model linkage information that describes presumed
dependencies between variables. FOS $\cal F = \{$$\cal F$$_1, $ $\cal F$$_2$$, ...\}$ 
represents a subset of powerset $\cal{P(I)}$ of $\cal{I}$, where $\cal{I}$$ =
\{0, 1, ..., D-1\}$ stands fos a set of indices and $D$ is a number of problem
variables (dimension of the fitness function). Each block $\cal F$$_j \in$ $\cal F$
contains the indices of those variables that are considered dependent. The block $\cal F$$_j$
divides the set of all variables into two mutually exclusive subsets of variables $\cal F$$_j$ and
$\cal F$ $\setminus$ $\cal F$$_j$. Variable within those subsets are crossed over
together~\cite[FOS].

Formally, within crossover for each individual $\vec{x}_i$, each block
$\cal F$$_j$ is iteratively considered in random order (crossover probability CR $= 1$).
For each block $\cal F$$_j$ is randomly generated new mutant vector $\vec{m}_i$ in the
same way as standard mutation. If the mutants values for variables contained in $\cal F$$_j$
are different from those contained in its parent $\vec{x}_i$, then these values are
overwritten in the parent $\vec{x}_i$, this produces $\vec{x}_{i,new}$ which is then
evaluated by the fitness function. New individual $\vec{x}_{i, new}$ is only accepted
if it has better or equal fitness value than the original $\vec{x}_i$. Changes in DE
pseudocode are captured in figure~\ref[DEFOSpseudocode].


\sec Linkage tree

Many FOS structures exist, and any of them can be used to model linkage structure.
However, this work focuses on two of them. The first of them is the \em linkage tree \em (LT).

“\em The Linkage Tree is the hierarchical cluster tree of the problem variables using
an agglomerative hierarchical clustering algorithm with a distance measure $\cal M$.
The distance measure $\cal M$$(X_1, X_2)$ measures the degree of dependency between
two sets of variables $X_1$ and $X_2$.\em”~\cite[LT]

There exist more potential distance measures $\cal M$$(X_1, X_2)$. However, in this work,
two distance measures are used. They are described in detail in the following chapter(~\ref[ch4]).

The linkage tree is a tree with $D$ leaf nodes and $D-1$ inner nodes, where $D$ is the number
of problem variables. Each node of the LT represents a specific block of variables $\cal F$$_j$.
The key property of the LT is that each $\cal F$$_j$, which contains more than one variable,
is the union of two other sets $\cal F$$_k$, $\cal F$$_l \in $$\cal F$, where $j \neq k \neq l$
(transitively). To put it more formally, for any subset $\cal F$$_j$, where $|\cal F$$_j| > 1$,
there exist subsets $\cal F$$_k, \cal F$$_l$ for which the following applies:

\begitems
\style N
*$\cal F$$_k, \cal F$$_l \neq \emptyset$
*$\cal F$$_k \cap \cal F$$_l = \emptyset$
*$\cal F$$_k \cup \cal F$$_l$ = $\cal F$$_j$
\enditems

The hierarchical clustering procedure starts by assigning each problem variable to a separate
block in random order. The procedure proceeds bottom-up. Therefore the tree is initialized with
these univariate blocks as leaves. In each step, a new node is created by merging two nodes of the
tree determined, by given distance measure $\cal M$, as the most dependent. It is
important to mention that each node can be merged only once. The merging process stops
when no more merges are possible. In other words, the root node has been created.
Due to the way the procedure works, the root node has to be a set of all problem variables.
The tree itself contains multiple levels of dependencies. From univariate level at the height of
zero to complete dependency between all variables at a depth of zero.~\cite[LT]

\midinsert \clabel[LTREE]{Linkage tree}
\picw=10cm \cinspic LT.png
\medskip
\caption/f Example Linkage tree~\cite[LTpic]
\endinsert


The DE using the LT structure (DE\_LT) build the LT in every generation.
Once the tree is built, DE\_LT traverses the tree in the opposite order of merging.

\sec Marginal product

The second introduced FOS structure is \em marginal product \em (MP)~\cite[MP]. The MP is
defined as set $\cal F$, where for each $\cal F$$_k, \cal F$$_l \in \cal F$ holds that
$\cal F$$_k \cap \cal F$$_l = \emptyset$. When all variables are independent, MP is called
univariate FOS and $\cal F$$ = \{\{0\}, \{1\}, ... , \{D-1\}\}$, where $D$ is number of problem
variables. On the contrary, when all variables are considered mutually dependent, MP is
called compact FOS.

Before introducing the \em MP building procedure\em, it is necessary to define the
\em strength of block \em $\cal S_{M}$$(\cal F$$_j)$, which determines dependency rate
within a certain block $\cal F$$_j$ according to the given distance measure $\cal M$.
The strength of block is defined as follows:

$$
{\cal S_M}({\cal F}_i) = \cases{ {G \over D-1} \sum_{v \in {\cal I}} {\cal M}({\cal F}_i,
\{v\}) & if $|{\cal F}_i| = 1$,\cr
{1 \over |{\cal F}_i| (|{\cal F}_i|-1)} \sum_{u \in {\cal F}_i} \sum_{v \in {\cal F}_i}
{\cal M}(\{u\}, \{v\}) & otherwise,} \eqmark
$$


\noindent where $G \geq 0$ is user-selected factor defining the degree of strength of 
univariate blocks.

The MP building procedure starts by initializing MP $\cal F$ as univariate FOS and by
assigning the strength of block to each block. In each step new block $\cal F$$_n$ is created
by merging two blocks ${\cal F}_a, {\cal F}_b \in \cal F$, which are determined
as the most dependent by the given distance measure $\cal M$. Then $\cal F$$_n$ is
assigned its strength of block. If newly created block meets the following conditions:

\begitems
\style N
*${\cal S_M}({\cal F}_n) \geq \theta_1, \theta_1 \in{\bbchar{R}}$
*${\cal S_M}({\cal F}_n) \geq K max({\cal S_M}({\cal F}_a), {\cal S_M}({\cal F}_b))$,
*$|{\cal F}_n| \leq \theta_2, \theta_2 \in{\bbchar{N}}$,
\enditems

\noindent where thresholds $\theta_1 > 0$, $\theta_2 \in [1, D]$ and  factor $K \in (0,1]$ are defined by user.
Then $\cal F$$_n$ is inserted into the FOS $\cal F$, and $\cal F$$_a, \cal F$$_b$ are 
removed from $\cal F$. The procedure runs until a newly created block $\cal F$$_n$ has not
met mentioned conditions or until MP has become the compact FOS.

The DE using the MP FOS structure (DE\_MP) build the MP in every generation.
After building the MP, DE\_MP traverses FOS in the opposite order of the merging, in
other words, from the last one added to FOS to the first one.


\midinsert \clabel[DEFOSpseudocode]{Differential evolution with known FOS}
\picw=14cm \cinspic DEFOSpseudocode.jpg
\medskip
\caption/f Pseudocode of the differential evolution with known FOS
\endinsert


\label[ch4] \chap Identification of the linkage structure

In the previous chapter, two possible representations of dependency structure were introduced.
In order to represent the dependency structure, it is necessary to determine the degree
of dependence between each pair of variables furthermore, between each pair of sets of
variables. The tool used to measure the degree is called the distance measure and is
denoted as $\cal M$.

Formally, $\cal M$ is a function that takes two sets of variables as input and produces a
real, positive number as output. $\cal M$ is defined as follows~\cite[LT]:

$$
{\cal M}(X_i, X_j) = {1 \over |X_i| |X_j|} \sum_{u \in X_i} \sum_{v \in X_j}
p_{u, v} \eqmark
$$

\noindent where $X_i$ and $X_j$ are sets of variables and $p_{u, v}$ is an element of the
\em dependency matrix \em $\cal P$ at position $u,v$.

The dependency matrix 

$$
%{\cal N} = \pmatrix{ a & b & \dot \cr c & d & \dot}
{\cal P} = \pmatrix{p_{0,0} & p_{0,1} & \dots & \dots & p_{0, D-1} \cr 
p_{1,0} & p_{1,1} & & & \vdots \cr
\vdots & & \ddots &  & \vdots \cr
\vdots & &  & \ddots & \vdots \cr
p_{D-1, 0} & \dots & \dots & \dots & p_{D-1, D-1}} \in {\bbchar R}^{D \times D}
$$

\noindent is a symmetric and positive semi-definite matrix.
The dependency matrix gives the dependency between each pair of variables.
The element $p_{i, j}$ denotes the pairwise dependency strength between i-th and j-th
problem variables. Consequently $\cal P$ contains zeros on diagonal i.e. $\forall i =
0, 1, ..., D-1 : p_{i, i} = 0$.

There are several methods how to construct the dependency matrix $\cal P$. Nevertheless,
this work focus only on two of them.

\sec Fitness-based method

The first method, called \em non-linearity check \em (NC), defines whether two
variables interact directly based on fitness values. The method works under
the assumption that non-linear interactions may exist only between dependent
variables. It classifies a pair of variables, either separable or non-separable,
by comparing the difference in overall fitness while making the exact same change for
a particular pair of chromosomes of given individual $x_{i, j}$ for different values of
$x_{i, k}, k \neq j$.~\cite[LINC, LIMD] Nevertheless, checking only one individual
is not convincing enough because there may exist linearity between a dependent pair
of variables in some context. Therefore more individuals must be checked. In this work,
$m$ best individuals from the population are checked.
The set of indices of $m$ best individuals in the population is denoted as $C$.

For each of chosen individuals $\vec{x}_i, i \in C$ and for each pair of variables $j$, $k$,
a pairwise dependency $d_{i,j,k}$ is calculated. The overall pairwise dependency between
those variables is determined by aggregating those values as following:

$$
p_{j, k} = {1 \over m} \sum_{i \in C} d_{i,j,k}.
$$

In order to calculate $d_{i,j,k}$, four individuals are picked by combining all possible
points that can be created by picking two different values for each $x_{i,j}$ and
$x_{i,k}$.~\cite[MAIN] The absolute value of differences in overall fitness value
for those point are used to calculate the potential dependence between \em j-th \em and
\em k-th \em variables by determining whether the adjustment to $x_{i,k}$ affect the change
in fitness caused by modification to $x_{i,j}$. Define:

$$
\Delta_{i, j} = |(f(\vec{x}_i) | x_{i, j} = a_j, x_{i, k} = a_k) - (f(\vec{x}_{i}) |
x_{i, j} = a_j + b_j, x_{i, k} = a_k)|,
$$
$$
\Delta_{i, j,k} = |(f(\vec{x}_i) | x_{i, j} = a_j, x_{i, }k = a_k + b_k) -
(f(\vec{x}_i) | x_{i, j} = a_j + b_j, x_{i, k} = a_k + b_k)|, 
$$

\noindent where $f$ denotes fitness function, $a_j, a_k, b_j, b_k$ can be any real value,
such that for every variable $j, a_{j}$ and $a_{j} + b_{j}$ remains within the bound
for $x_{i,j}$ inside the current population, to put it more formally:

$$
\forall j :\max_{\vec{x}_i \in P}(x_{i,j}) \geq a_j \geq \min_{\vec{x}_i \in P}(x_{i,j}),
$$

$$
\forall j :\max_{\vec{x}_i \in P}(x_{i,j}) \geq a_j+b_j \geq \min_{\vec{x}_i \in P}(x_{i,j}),
$$

\noindent nevertheless, in this work are used values that have been empirically found
for~\cite[MAIN], which are

$$
a_j = \min_{\vec{x}_i \in P}(x_{i, j}) + (\max_{\vec{x}_i \in P}(x_{i, j}) -
\min_{\vec{x}_i \in P}(x_{i, j})) * 0.35,
$$

$$
b_j = (\max_{\vec{x}_i \in P}(x_{i, j}) - \min_{\vec{x}_i \in P}(x_{i, j})) * 0.35.
$$

Finally, \em j-th \em and \em k-rh \em are said to be dependent when $|\Delta_{i,j} -
\Delta_{i, j,k}| \geq 0$, the pairwise dependency $d_{i,j,k}$ is defined as:

$$
d_{i,j,k} = \cases{1 - {\Delta_{i,j,k} \over \Delta_{i,j}} & if $\Delta_{i,j} \geq \Delta_{i,j,k}$,
\cr 1 - {\Delta_{i,j} \over \Delta_{i,j, k}} & otherwise.} \eqmark
$$

\noindent Note that $d_{i,j,k}$ as well as $p_{j,k}$ lie within $[0, 1)$ with zero indicating
independent variables.


\sec Distribution-based method
The second method to construct the dependency matrix $\cal P$ is called the \em maximal
information coefficient \em (MIC)~\cite[MIC]. There exist more methods used to identify
dependencies between a pair of variables based on the distribution of the
population~\cite[MP, MAIN]. However, MIC achieved better accurancy in comparison to other
methods.~\cite[MIC, MIC2]

MIC is based on the idea that if a relationship between a pair of variables exists,
then it is possible to draw a grid on the scatterplot of the two variables that partitions
the data to encapsulate that relationship.

In order to calculate MIC, all possible grids up to maximal grid resolution are considered. Note
that maximal grid resolution depends on the sample size. For each pair of integers $(x, y)$
the largest possible mutual information (MI)~\cite[MI] achievable by any x-by-y grid applied
to the data is computed. Those mutual information values are then normalized by the logarithm
of the minimum $x$ and $y$. Finally, MIC is defined as the maximum of those highest normalized
mutual information values.~\cite[MIC] Formally:

$$
MIC_{i,j} = \max_{(x,y) : x \leq B, y \leq B} \Bigg( \max_{g : G_{x, y}} \Big( {MI_{i,j}|_g
\over \log \min(x, y)} \Big)\Bigg),
$$

\noindent where $B$ is user-specified value defining maximal grid resolution, $G_{x,y}$ denotes
a set of all possible x-by-y grids, and $MI_{i,j}|_g$ stands for mutual information of $i$-th and
$j$-th variables achieved by application of grid $g$.

As was mentioned above MIC has achieved good results in various comparisons. However, a big
limitation of MIC is its high computational cost. Therefore several algorithms for
approximating the MIC have been published.~\cite[MIC, TIC, GMIC]. In this work MICE
minepy implementation~\cite[MICE, MINEPY] is used.

In this work, MICE is not calculated from the whole population, but only subset $C$ of all
individuals from the current population is considered. The dependency matrix $\cal P$ is then
formally calculated as following:


\centerline{$p_{i,j} = $ MICE$_{i,j}|_C$.}



\label[ch5] \chap Experiments

In \ref[s23] section, the standard differential evolution was introduced. It was also noted
that DE does not have any tool to recognize or model the linkage information between certain
parts of the solution. In chapter \ref[ch3], two possible
representations of dependency structure were introduced assuming known pairwise dependencies,
and in chapter ~\ref[ch4], two ways to find pairwise dependencies and thereby build the dependency matrix
$\cal P$ were presented.

Based on those methods, it is possible to propose adjusted DE with dependency detection. The
adjusted version differs from the original in two factors. Firstly, in every generation, the
dependency matrix $\cal P$ and FOS structure based on it is built. Secondly, the crossover is
modified to respect dependent blocks.

\midinsert \clabel[DE final]{Differential evolution with dependency detection}
\picw=14.7cm \cinspic DE_final.png
\bigskip
\caption/f Pseudocode of the differential evolution with dependency detection
\endinsert

The main goal of experiments is to study the performance of various types of DE with dependency
detection differing in creating the matrix $\cal P$, or in the building of FOS $\cal F$. Compare
them between each other and with standard DE and other optimization algorithms.

\label[s51] \sec Algorithms

\label[s511] \secc Differential evolution variants

Within the experiments, seven types of differential evolution are compared. The original DE,
as was introduced in~\ref[s23] section. (DE\_UNIFORM). The remaining six variants of DE are divided
into three pairs according to how they create the distance matrix $\cal P$. Within each pair,
the first variant uses the linkage tree (LT) and the second the marginal product (MP). The first
pair uses the non-linearity check to create $\cal P$ (DE\_LT\_NC and DE\_MP\_NC). The second
pair take advantage of maximal information coefficient (DE\_LT\_MIC and DE\_MP\_MIC). The third
pair are DE variants with full prior knowledge of pairwise dependencies. Therefore they build
optimal $\cal P$, which is (0, 1)-matrix with zeros for independent pairs and ones for
dependent pairs (DE\_LT+ and DE\_MP+).

\midinsert \clabel[DEvariants]{Differential evolution variants}
\ctable{cccc}{
\hfil 
& Non-linearity check & Max. inf. coeff. & Optimal \crl \tskip4pt
Linkage tree & DE\_LT\_NC & DE\_LT\_MIC & DE\_LT+ \cr
Marginal product & DE\_MP\_NC & DE\_MP\_MIC & DE\_MP+ \cr
}
\caption/t Overview of newly proposed variants of the differential evolution.
\endinsert

\noindent It is important to note that all newly proposed variants of DE create $\cal P$
and build the FOS structure in every second generation instead of every generation in order
to speed up computing.

\noindent All above-mentioned DE variants share the following:

\begitems
*Initialization of individuals $\sim {\cal N}({\bf 0},100 \cdot {\bf I}_D)$, where $\cal N$ is
multivariate normal distribution, $\bf 0$ stands for the zero vector, and ${\bf I}_D$ represents
$D \times D$ identity matrix.
*The differential weight $F = 0.7$
\enditems

\noindent Other parameters:

\begitems
*The crossover probability for DE\_UNIFORM: $CR = 0.9$
*The degree of strength of univariate blocks:
$$
G = \cases{ 1 & for DE\_MP+,\cr
2 & otherwise.} 
$$
*Threshold $\theta_1$ defining the minimal strength of block to be accepted:

$$
\theta_1 = \cases{ 10^{-1} & for DE\_MP\_MIC,\cr
10^{-8} & otherwise.} 
$$
*Maximal size of block: $\theta_2 = 6$
*Maximum potential degree of strength of block reduction during merging

$$
K = \cases{ 0.8 & for DE\_MP+,\cr
0.4 & for DE\_MP\_NC,\cr
0.7 & for DE\_MP\_MIC.} 
$$

*Number of checked individuals within non-linearity check method: $m = \lceil0.15 \cdot NP\rceil$
*The subset used to calculate MICE $C = C_b \cup C_r$, where $C_b$ is set of $\lceil 0.3 \cdot
NP\rceil$ best individuals in population and $C_r$ is a set of $\lceil 0.1 \cdot NP\rceil$
randomly chosen individuals from the remaining.
*The maximal MICE grid resolution $B$ is set according to table~\ref[T52] (rounded to the
nearest integer in an upward direction).
\midinsert \clabel[T52]{MICE grid resolution \em B \em}
\ctable{ll}{
\hfil 
Number of samples & B parameter\crl \tskip4pt
$|C| < 25$ & $ |C|^{0.85}$ \cr
$25 \leq |C| < 50$ & $|C|^{0.8}$ \cr
$50 \leq |C| < 250$ & $|C|^{0.75}$ \cr
$250 \leq |C| < 500$ & $|C|^{0.7}$ \cr
$500 \leq |C| < 1000$ & $|C|^{0.65}$ \cr
$1000 \leq |C| < 2500$ & $|C|^{0.60}$ \cr
$2500 \leq |C| < 5000$ & $|C|^{0.55}$ \cr
}
\caption/t The dependence of the cardinality of $C$ on the parameter $B$, taken
from~\cite[MICE].
\endinsert

*Th MICE parameter $c$, which determines how many more clumps
there will be than columns in every partition, was set default value $15$~\cite[MICE]
\enditems


\noindent All values mentioned above were found empirically unless otherwise stated.

\secc Other algorithms

The Covariance matrix adaptation evolution strategy (CMA-ES) belongs to the class of
evolutionary algorithms. CMA-ES is considered state-of-the-art in evolutionary
computation and has very quickly become the standard tool for continuous
optimization.~\cite[CMAES1, CMAES2, CMAES3]
In this work the Hanses's implementation of CMA-ES with default parameters is
used.~\cite[CMAESIMPLEMENTATION]

The last considered algorithm is the Nelder-Mead simplex algorithm~\cite[FMIN], the optimization
algorithm, which is not an evolutionary algorithm. Nevertheless, it uses only function values
to find the optimum. Therefore may be used for black box optimization. The Scipy implementation
called FMIN is used~\cite[SCIPY]. Minimal absolute difference in candidate solution between
iterations (\em xtol \em) as well as minimal absolute difference in fitness function values
between iterations (\em ftol \em) is set to $10^{-12}$. Independent restarts are allowed.



\sec Test problems

The first set of benchmarking problems is called Test problems. These six
optimization problems to minimize are considered to study the impact of various types of
linkage learning on the performance of DE and to benchmark considered algorithms.

Before the introduction of the Test problems, state the important property of functions, the
\em additive separability\em. Define additively separable function $F$ as:

$$
F(x_0, x_1, ..., x_{D-1}) = f_0(x_0) + f_1(x_1) + ... + f_{D-1}(x_{D-1}),
$$

\noindent where $f_0, f_1, ..., f_{D-1}$ are functions of one variable. It is crucial that
the optimum of D-dimensional additively separable function may be obtained by performing
D independent one-dimensional optimizations along each dimension, formally:

$$
\min_{[x_0, x_1, ..., x_{D-1}] \in{\bbchar{R}^D},} F(x_0, x_0, ..., x_{D-1}) = \min_{x_0 \in{\bbchar{R}}}
f_0(x_0) + \min_{x_1 \in{\bbchar{R}}} f_1(x_1) + ... + \min_{x_{D-1} \in{\bbchar{R}}} f_{D-1}
(x_{D-1})
$$

It can be seen that standard DE, which optimizes each dimension independently, would be suitable
for optimizing additively separable functions.

\secc Sphere

The first benchmark function is th sphere function, also known as De Jong F1~\cite[DEJONG].
It is presumable the easiest continuous domain optimization problem. It is convex, separable,
and has one local minimum.

Definition of the sphere function:
$$
f_{sphere}(\vec{x}) = \sum_{i=0}^{D-1}x_i^2
$$
Global minimum:
$$
f_{sphere}(\vec{x}_{min}) = 0
$$
$$
\vec{x}_{min} = [0, 0, ..., 0]
$$


\secc Levy

The second considered benchmark problem is the Levy function~\cite[LEVY]. Like the sphere, it
is a separable function with one local minimum. Nevertheless, the Levy function is considered more
difficult to optimize.

The Levy function is defined as follows:
$$
f_{Levy}(\vec{x}) = \sin^2(\pi v_0) + \sum_{i=0}^{D-2}\Big[(v_i -1)^2 (1 + 10\sin^2(\pi v_i +1)
)\Big] + (v_{D-1} - 1)^2 (1 + sin^2(2\pi v_{D-1})), 
$$
\noindent where $v_i = 1 + {x_i -1 \over 4}$, for all $i = 0, 1, ..., D-1$.
\medskip
\noindent Global minimum:
$$
f_{Levy}(\vec{x}_{min}) = 0
$$
$$
\vec{x}_{min} = [1, 1, ..., 1]
$$

\secc Rastrigin

The Rastrigin function~\cite[RASTRIGIN, RASTRIGIN2] is the third benchmark problem. Like the
previous functions, this one is also separable. It is a difficult function to optimize. Due
to regular ‘‘noise'', it has many regularly distributed local minimum. The Rastrigin function
is defined as:
$$
f_{Rastrigin}(\vec{x}) = 10 \cdot D + \sum_{i=0}^{D-1}\Big [x_i^2 - 10\cos(2\pi x_i) \Big]
$$
Global minimum:
$$
f_{Rastrigin}(\vec{x}_{min}) = 0
$$
$$
\vec{x}_{min} = [0, 0, ..., 0]
$$

\secc Rosenbrock
The Rosenbrock function~\cite[ROSENBROCK], also known as the Banana function, is the first
considered non-separable function because it has overlapping dependencies. Each pair of
consecutive variables is dependent. The Rocenbrock function contains a narrow, parabolic valley,
where the global minimum is located. However, even though this valley is easy to find,
convergence to the minimum is difficult~\cite[HARDROSENBROCK]. The definition of Rosenbrock
function is as follows:
$$
f_{Rosenbrock}(\vec{x}) = \sum_{i=0}^{D-2} \Big [100 (x_{i+1} - x_i^2)^2 + (1 - x_i)^2\Big]
$$
Global minimum:
$$
f_{Rosenbrock}(\vec{x}_{min}) = 0
$$
$$
\vec{x}_{min} = [1, 1, ..., 1]
$$

\secc SoREB

The Sum of Rotated Ellipsoid Blocks or abbreviated SoREB~\cite[MP] is defined as follows:
$$
f_{Ellipsoid}(\vec{x}) = \sum_{i=0}^{l-1} \Big [10^{{6i \over l-1}}x_i^2\Big]
$$
$$
f_{SoREB}(\vec{x}, k) = \sum_{i=0}^{D/k-1} \Big[f_{Ellipsoid}\big(R_\theta([x_{ki}, ..., x_{k(i+1)-1}])\big) \Big]
$$

\noindent $R_\theta$ defines the rotation of a vector around the origin by the angle of
$\theta$, and $k$ is the size of block. Rotated blocks of variables that enter to
$f_{ellipsoid}$ as an input creates strongly connected components. Variables within the block
have strong dependencies but are entirely independent of any variables outside their block.
This feature is called block-separability.

Within comparison, four types of the SoREB function differing in the size of blocks (2, 3, 4, 5)
were considered. The rotation of $\theta = {\pi / 8}$ is used.

\noindent Global minimum:
$$
f_{SoREB}(\vec{x}_{min}, k) = 0; k \in{\bbchar{N}}
$$
$$
\vec{x}_{min} = [0, 0, ..., 0]
$$



\secc OSoREB

The SoREB function conations only non-overlapping non-decomposable block of size $k$. In~\cite[MP]
the overlapping version of this problem was defined as OSoREB (Overlapping Sum of Rotated
Blocks). In addition to the original SoREB problem, SoREB blocks of length 2 for every
pair of successive variables belonging to other original blocks are used. For OSoREB
is used $k = 5$ and $\theta = \pi / 8$. Definition of OSoREB:
$$
f_{OSoREB}(\vec{x}, k) = f_{SoREB}(\vec{x}, k) + \sum_{i=1}^{D/k-1} \Big [f_{Ellipsoid}\big(R_\theta([x_{ki-1}, x_{ki}])\big)\Big]
$$
Global minimum:
$$
f_{OSoREB}(\vec{x}_{min}, k) = 0; k \in{\bbchar{N}}
$$
$$
\vec{x}_{min} = [0, 0, ..., 0]
$$


\sec Black Box Optimization Benchmarking problems

Black Box Optimization Benchmarking (BBOB) problems are the second considered set of
benchmark problems. It is a set of 24 noise-less real-parameter single-objective benchmark
functions defined in ~\cite[BBOBFUNC] as Real-Parameter Black-Box Optimization Benchmarking
2009 Noiseless Functions. Those functions were used for the BBOB workshop 2009.
The BBOB problems were selected with the intention to evaluate the performance of algorithms
with regard to standard difficulties that occur in continuous domain search. So they
definitely should, at least to a certain extent, reflect problems that are dealt with in
practice. All BBOB problems are to be minimized.

It is important to note that since BBOB problems cover a wide range of possible optimization
problems, proposed DE variants may be unsuitable for some of them.BBOB problems consist of
separable and non-separable ones.



\sec Setup

All experimental results described in this work measures the first time a global
optimum was hit. In other words, the number of fitness function calls needed to reach the
small enough neighborhood of the global optimum for the first time within the run.
The toleration is $10^{-8}$.
\label[s541] \secc Test problems specifics

For each problem, each algorithm, and each dimension, twenty-five
independent runs are performed. The performance is considered successful if at least 24 runs
converged to the global optimum or to a predefined sufficiently close approximation within
$300000 \cdot D$ calls of the fitness function. 

The associate population size of evolutionary algorithms is the smallest possible size so that
the algorithm's performance is considered successful. It is determined by starting from the
smallest possible population and letting the algorithm runs 25 times. If the performance 
has not been successful, the population size for the next trial will increase by $s$. This
procedure is repeated until the successful population size is found or a population size
reaches the upper limit $T$. If the successful population size is found, the optimal population
size is searched for by performing a bisection search between the current population size and
the previous size. Otherwise, the algorithm is considered unable to optimize a certain problem
and dimension.
Parameters $s$ and $T$ are set as follows:

$$
s = \cases{ 10 & for DE\_LT\_MIC and DE\_MP\_MIC,\cr
4 & for otherwise.} 
$$

$$
T = \cases{ 50 + 6 \cdot D & for DE\_LT\_MIC and DE\_MP\_MIC,\cr
50 & for otherwise.} 
$$

\secc BBOB problems specifics

The setup for BBOB problems is partially determined by the authors of BBOB problems in
\cite[BBOBSETUP].
For each algorithm, dimension, and optimized function, five different function \em instances \em
are used, each of them three times. The number of fitness function calls is limited to
$1000000 \cdot D$. The population size is set to 25, except for algorithms using MIC, for which
it is increased to 50. For BBOB problems, algorithms DE\_LT+ and DE\_MP+ are not considered.

BBOB problems evaluation and results visualization are provided by COCO (COmparing
Continuous Optimizers) platform~\cite[COCO].


\label[ch6] \chap Results

In this chapter, the results of experiments introduced in the previous chapter are
presented. The results are divided into two sections.


\label[s61] \sec Test problems
Firstly, results of the performance of the algorithms introduced in section \ref[s51] on the
Test problems. Results are visualized in the form of graphs, which show the dependence of
the number of fitness function calls on the dimension of a certain problem. These graphs are
called scalability graphs. They show the most important facets of the algorithm's performance.
Moreover, they provide a prediction regarding the performance on higher-dimensional problems.

Each data point is the median of successful runs.
To display data over a very wide range of values in a compact way and to get clearer results,
a base-10 logarithmic scale is used for both axes of graphs. It is also worth noting that
the y-axis does not start at zero.

The Test results may be divided into three groups according to separability into separable
problems (sphere, Levy, Rastrigin), block-separable problems (SoREB), and non-separable
problems (Rosenbrock, OSoREB).

\secc Separable problems

The results on separable problems are shown in figure~\ref[separable].

Both algorithms with full prior knowledge (DE\_LT+, DE\_MP+) perform very similarly for
all three separable problems. DE\_LT+ is a bit better for the easiest function (sphere).
Nevertheless, for more difficult problems, the DE\_MP+ achieves
a little better results than DE\_LT+ (for Levy and Rastrigin).

Since separable problems do not contain any dependencies between variables, it is not
surprising that there is almost no difference in DE\_LT\_MIC and DE\_LT+ performance
because, for separable problems, all possible linkage trees should be equally good. Therefore
it does not matter what dependency matrix $\cal P$ DE\_LT\_MIC finds and subsequently what
linkage tree it builds. The linkage tree would be just as good as the one built by DE\_LT+.

The DE\_MP\_MIC is slightly worse than DE\_LT+, DE\_MP+, and DE\_LT\_MIC, especially for higher
dimensions. It is very hard to recognize separability by MIC because the DE selection
operator aligns individuals with the fitness contours. Therefore DE\_MP\_MIC may determine
some variables as dependent and build suboptimal MP-FOS, which results in worse performance.

Although both algorithms using non-linearity check (DE\_LT\_NC, DE\_MP\_NC) correctly
recognize the separability of the problem and build optimal FOS, they have achieved significantly
worse results than other newly-introduced variants of DE. The difference is mainly caused by the
fact that DE\_LT\_NC and DE\_MP\_NC uses fitness function evaluations to find dependencies, in
contrast with DE\_LT+, DE\_MP+, and DE\_LT\_MIC, which also build optimal FOS but do not waste
fitness function evaluations.

It also provides an explanation of why the DE\_LT\_NC outperforms DE\_MP\_NC. Since
DE\_LT\_NC, DE\_MP\_NC build optimal FOS, the DE\_LT\_NC performs comparably to DE\_LT+
within the crossover. Similar to DE\_MP\_NC and DE\_MP+. Moreover, since DE\_LT+ and DE\_MP+
perform similarly, DE\_LT\_NC and DE\_MP\_NC use a comparable number of fitness function
evaluations within the crossover. It is a fact that LT FOS has a necessarily higher
cardinality than MP FOS for the same dimension. Therefore DE\_LT\_NC finds the optimum
within a fewer number of generations than DE\_MP\_NC. Since the dependency matrix is built
in every second generation, DE\_MP\_NC uses more fitness function calls to find dependencies,
resulting in worse performance than DE\_LT\_NC.

CMA-ES has achieved interesting results. For the sphere function, CMA-ES is a constant factor
better than DE\_LT+, DE\_MP+, DE\_LT\_MIC, DE\_MP\_MIC. Nevertheless, as the difficulty of
optimization of functions grows, the performance of CMA-ES is getting worse. For the Levy function,
CMA-ES performs similarly to the four mention algorithms, and for the hardest function (Rastrigin),
CMA-ES is significantly worse and achieves results comparable to DE\_LT\_NC and DE\_MP\_NC.
However, it is worth noting that CMA-ES scales better than NC variants of DE.

Finally, FMIN outperforms all algorithms for low dimensions of the sphere. Nevertheless, it scales
very badly and gets outperformed by all algorithms in higher dimensions. FMIN is unable to find
optimum, even for low dimensions, of harder functions as Levy and Rastrigin.

\midinsert \clabel[separable]{Separable problems graphs}
\picw=17.3cm \cinspic separable.png
\caption/f Scalability graphs of separable problems. Each point is the median of
successful runs.
\endinsert

\secc Block-separable problems

The results on block-separable problems are shown in figure~\ref[BLOCKSEPARABLE].

The separable problems are represented by the SoREB function with variable size of block
(2, 3, 4, 5). It is worth noting the relationship between particular pair of DE variants
that use the same technique to build the dependency matrix.

Firstly, the DE\_MP+ is a constant factor better than DE\_LT+. It is not surprising since
the block-separable structure of a problem may be represented by MP FOS very well.

However, for the second pair, which uses the non-linear check, it can be seen that the LT variant
(DE\_LT\_NC) outperforms the MP variant (DE\_MP\_NC). Although DE\_MP\_NC builds the same FOS as
DE\_MP+, which perfectly captures the problem's structure, it cannot achieve better
results than DE\_LT\_NC. It points to the fact that worse performance within the crossover
is compensated by a lower number of fitness function evaluations used to find dependencies.

Lastly, MIC variants (DE\_LT\_MIC, DE\_MP\_MIC) perform almost similarly for block sizes two
and three. For $k = 4$ and $k = 5$, DE\_LT\_MIC achieves better results than DE\_MP\_MIC
for lower dimensions,
nevertheless, for the higher dimensions, the dependent blocks are easier to
recognize, and the DE\_MP\_MIC outperforms DE\_LT\_MIC.

The relationship between MIC variants and NC variants is also worth noting. It can be seen
that for $k = 2$, both MIC variants perform similarly to DE\_LT+ and better than NC variants.
However, as the size of block increases and more dependencies occur, MIC variants are getting
outperformed by NC variants. It is caused by the weaker ability of MIC to recognition dependencies.

The original DE\_UNIFORM performance shows up as the worst of all considered algorithms for
block-separable problems. For bigger sizes of block the DE\_UNIFORM is even worse.

CMA-ES perform similarly for all SoREB variants, regardless of the size of blocks, in
terms of the required number of evaluations. Since other algorithms need more evaluations
for SoREB with bigger blocks, CMA-ES outperforms all algorithms except DE\_MP+ for
$k = 5$. Nevertheless, DE\_LT+ and DE\_MP+ outscale CMA-ES, which scalability is
comparable to DE\_LT\_NC and DE\_MP\_NC.

Last considered algorithm FMIN shows best results for small dimension, but the worst
scalability of all algorithm and inability to find optimum for higher dimensions.

Lastly, note that DE\_LT+ and DE\_LT\_NC need, on average, more evaluations to find optimum for
$D = 5$ than for $D = 8$ if $k = 5$, which shows certain limitations of LT when all variables
are pairwise dependent.

\midinsert \clabel[BLOCKSEPARABLE]{Block-separable problems graphs}
\picw=17.3cm \cinspic block-separable.png
\bigskip
\caption/f Scalability graphs of block-separable problems. Each point is the median of
successful runs.
\endinsert

\secc Non-separable problems

The results on non-separable problems are shown in figure~\ref[NonSEPARABLE].

Firstly, it is worth noting that no DE variant that builds MP-FOS is capable of finding
the optimum of presented non-separable problems, even for a small dimension. It is probably
caused by the overlapping dependency structure of both problems, which is impossible to
model by MP-FOS.

DE\_LT+ and DE\_LT\_MIC perform almost identically. The same trend may be observed in figure
\ref[separable]. Representing results on separable functions. For the Rosenbrock DE\_LT+ and
DE\_LT\_MIC scale better than DE\_LT\_NC. Nevertheless, for OSoREB, DE\_LT+ and DE\_LT\_MIC
are only a constant factor better than DE\_LT\_NC. The slightly better relative scalability
towards of DE\_LT\_NC on OSoREB towards DE\_LT+ and DE\_LT\_MIC corresponds to the results
obtained in \ref[BLOCKSEPARABLE] because OSoREB is in a sense closer to the block-separable
problem than Rosenbrock, and the dependency structure of OSoREB may be captured better within
LT-FOS than the structure of Rosenbrock. Therefore the impact of correct recognition of
dependencies, which DE\_LT\_NC does, increases.

The same phenomenon may be seen in the performance of DE\_UNIFORM, which is a constant
better than DE\_LT\_NC for Rosenbrock, the function with a relatively small number of
dependencies. Nevertheless, as the  number of dependencies increases from Rosenbrock to
OSoREB, the scalability of DE\_UNIFORM gets worse, and DE\_UNIFORM is unable to find
the optimum of OSoREB in higher dimensions.

On the other hand, the opposite trend can be viewed in the performance of CMA-ES, which
outperforms all other algorithms. Nevertheless, for the Rosenbrock, the difference is less
significant, and DE\_LT+ and DE\_LT\_MIC seemed to scale better than CMA-ES.

For non-separable problems, similarly as for other
FMIN show up as the best algorithm for low dimensions, but
scale the worst. Therefore is almost useless for higher dimensions.


\midinsert \clabel[NonSEPARABLE]{Non-separable problems graphs}
\picw=17.3cm \cinspic non-separable.png
\bigskip
\caption/f Scalability graphs of non-separable problems. Each point is the median of
successful runs.
\endinsert


\sec BBOB problems


The results on the BBOB problems are presented by graphs of Empirical cumulative distribution
functions (ECDFs)~\cite[ECDF]. These ECDFs show on the y-axis the proportion of cases for which
the number of fitness function evaluations needed to find the optimum was smaller than the value
given on the x-axis. For the x-axis, a base-10 logarithmic scale is used, and the total number of
fitness function evaluations is divided by dimension. Each graph also shows theperformance of the
best algorithm of BBOB workshop 2009 noted as \em best 2009 \em.

All results in this section were obtained by the COCO platform. Complete results contains
25 function for various dimensions (2, 3, 5, 10, 20, 40). Complete results are shown in
Appendix~\ref[APPB].
In this section, only selected functions of dimensions 5 and 20 occur. 
These functions were chosen to represent the characteristic trend seen for more functions.

Firstly, the set of functions on which all DE variants perform similar but worse than CMA-ES
and best 2009. This set is represented by the so-called Ellipsoid separable function in
figure~\ref[ELLIPSOIDSEP].

\midinsert \clabel[ELLIPSOIDSEP]{Ellipsoid separable function graphs}
\picw=.4\hsize
\centerline {\inspic Ellipsoid5.png \hfil\hfil \inspic Ellipsoid20.png }\nobreak
\medskip
\caption/f Graphs of the empirical cumulative distribution functions of the introduced algorithms
on the Ellipsoid separable function for dimensions five and twenty.
\endinsert

Secondly, for a number of functions, MP variants of DE are outperformed by other DE variants,
especially for higher dimensions. Nevertheless, LT and UNIFORM variants are outperformed by
CMA-ES and by best 2009. An example of such a function may be seen in figure~\ref[BENT].

\midinsert \clabel[BENT]{Bent function graphs}
\picw=.4\hsize
\centerline {\inspic Bent5.png \hfil\hfil \inspic Bent20.png }\nobreak
\medskip
\caption/f Graphs of the empirical cumulative distribution functions of the introduced algorithms
on the Bent function for dimensions five and twenty.
\endinsert

The third observed trend within BBOB functions is a significantly worse performance of DE
variants against CMA-ES and best 2009. DE variants are unable to find the global optimum
for the majority of these functions, especially in higher dimensions. Note that these
functions are mainly Multi-modal functions with a weak global structure. This trend is
captured in figure~\ref[GRIEWANK].

\midinsert \clabel[GRIEWANK]{Griewank function graphs}
\picw=.4\hsize
\centerline {\inspic Griewank5.png \hfil\hfil \inspic Griewank20.png }\nobreak
\medskip
\caption/f Graphs of the empirical cumulative distribution functions of the introduced algorithms
on the Ellipsoid separable function for dimensions five and twenty.
\endinsert


\chap Conclusion

The main goal of this work was to propose a crossover operator with dependency detection
for DE.

In chapter~\ref[ch3] were introduced two representations of the dependency structure, the linkage
tree (LT), which contains multiple levels of dependencies, from univariate level to
complete dependency, and the marginal product (MP), which contains every problem variable exactly once.

In chapter~\ref[ch4], two approaches to find pairwise dependencies between variables were
introduced. Firstly, the fitness-based approach called non-linearity check (NC) determines the
possible dependence between a pair of variables according to the fitness values. Secondly, an
approach called maximal information coefficient (MIC) identifies dependencies based on the 
distribution of the population.

Subsequently, six new variants of DE differing in the crossover operator were proposed in 
section~\ref[s51]. Except for four regular variants using the above-mention methods
DE\_LT\_NC, DE\_MP\_NC, DE\_LT\_MIC, DE\_MP\_MIC, two artificial variants with full prior
knowledge of dependency structure were also proposed (DE\_LT+, DE\_MP+). 

According to the results presented in section ~\ref[s61], newly proposed methods show to achieve
fair scalability. All of them outscale the original DE (DE\_UNIFORM) for almost all test
problems, independent of the dependency structure. They also showed better scalability than
the FMIN algorithm, and for some problems, even better scalability than state-of-the-art
evolutionary algorithm CMA-ES. The usage of any of four proposed regular variants of DE instead
of the original one would bring better performance.

According to the results from the previous chapter, it may be concluded that linkage tree
representation, thanks to its robustness, seems to be a better choice than marginal
product representation.

It is worth noting that the results obtained by our NC methods should be compared to
the MIC results with careful consideration. For instance, while NC methods can easily recognize
the separability of two variables, the same task is challenging for MIC ones because the DE selection
operator aligns individuals with the fitness contours. On the other hand, MIC variants, in
contrast with NC ones, do not need any fitness function evaluations to find dependencies.
The disadvantage of MIC is that DE usually takes advantage of relatively small populations, and
since MIC is a statistical method, it achieves better results with more samples. On the other
hand, MIC would probably be more noise resistant than NC. However, no experiments to
substantiate this assumption have not been presented so far, so there is space for future
work to prove or refute this hypothesis.

Although all four regular variants of DE enhance the performance of the original DE,
they have some limitations which would be reduced by further adjustments.

For instance, \em incremental dependency updating \em described in~\cite[MAIN] would
probably significantly reduce the amount of fitness function evaluations used by NC methods
to find dependencies and decrease the difference in performance between NC methods
and methods with full prior knowledge.

The last unanswered question is how to deal with problems containing overlapping
sub-components. Not LT nor MP are able to represent these types of structures very
well. Moreover, the optimal linkage structure of these problems is unknown. So to
find the optimal structure for these problems would also be very interesting.

\bibchap
\usebib/c (simple) myreferences


\app Abbreviations

\medskip
\bgroup \leftskip=5.5em

\abbrv[BBOB]  Black box optimization benchmarking

\abbrv[CMA-ES]  Covariance matrix adaptation evolution strategy

\abbrv[COCO]  Comparing continuous optimizers

\abbrv[DE] Differential evolution

\abbrv[DE\_LT]  Differential evolution which uses the linkage tree to represent the structure of a problem

\abbrv[DE\_LT+]  Differential evolution which uses the linkage tree to
represent the structure of a problem and has full prior knowledge of pairwise
dependencies

\abbrv[DE\_LT\_MIC]  Differential evolution which uses the linkage tree to
represent the structure of a problem and finds dependencies by maximal information coefficient

\abbrv[DE\_LT\_NC]  Differential evolution which uses the linkage tree to
represent the structure of a problem and finds dependencies by non-linearity check

\abbrv[DE\_MP]  Differential evolution which uses the marginal product to represent the structure of a problem

\abbrv[DE\_MP+] Differential evolution which uses the marginal product to
represent the structure of a problem and has full prior knowledge of pairwise
dependencies

\abbrv[DE\_MP\_MIC]  Differential evolution which uses the marginal product to
represent the structure of a problem and finds dependencies maximal information coefficient

\abbrv[DE\_MP\_NC]  Differential evolution which uses the marginal product to
represent the structure of a problem and finds dependencies by non-linearity check

\abbrv[DE\_UNIFORM]  The original version of differential evolution

\abbrv[EA]  Evolutionary algorithm

\abbrv[ECDFs]  Empirical cumulative distribution functions

\abbrv[FOS]  Family of subsets

\abbrv[LT]  Linkage tree

\abbrv[MI]  Mutual information

\abbrv[MIC]  Maximal information coefficient

\abbrv[MP]  Marginal product

\abbrv[NC]  Non-linearity check

\abbrv[OSoREB]  Overlapping Sum of Rotated Ellipsoid Blocks function

\abbrv[SoREB]  Sum of Rotated Ellipsoid Blocks function

\par\egroup


\label[APPB]  \app Complete BBOB results

\app Implementation and contents of CD

Here a brief description of a program used to generate results~\ref[ch6] is provided.
All source codes together with README.txt file are on the enclosed CD.
The program offers two functionalities for users.

Firstly, the procedure of finding the population size of chosen algorithms for chosen
problems and dimensions as was described in section~\ref[s541].

Secondly, finding the median over successful runs of the selected algorithm for selected
problem and dimension.

The contents of CD:

\begitems
*BcThesis.pdf
*comparison.c
*comparison.h
*fitnessFunctions.c
*fitnessFunctions.h
*main.c
*Makefile
*mine.c~\cite[MINEPY]
*mine.h~\cite[MINEPY]
*parameters.c
*parameters.h
*README.txt
*search.c
*search.h
*utils.c
*utils.h
\enditems

\bye