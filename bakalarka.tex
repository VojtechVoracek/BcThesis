% The documentation of the usage of CTUstyle -- the template for
% typessetting thesis by plain\TeX at CTU in Prague
% ---------------------------------------------------------------------
% Petr Olsak  Jan. 2013

% You can copy this file to your own file and do some changes.
% Then you can run:  pdfcsplain your-file
\input ctustyle2  % The template (in version 2) is included here.
%\input pdfuni    % Uncomment this if you need accented PDFoutlines
\input opmac-bib % Uncomment this for direct reading of .bib database files 
%\input my_references.bib



\worktype [B/EN]
\faculty {F3}
\department {Department of Cybernetics}
\title {Differential Evolution Crossover with Dependency Detection}
\titleCZ {Křížení pro diferenciální evoluci s detekcí závislostí}
\author {Vojtěch Voráček}
\date {March 2021}

\pagetwo    {}  % The text printed on the page 2 at the bottom.

\abstractEN {
   This document shows and tests an usage of the plain\TeX{} officially
   (may be) recommended design style {\ssr CTUstyle} for bachelor (Bsc.), master
   (Ing.), or doctoral (Ph.D.) theses at the Czech Technical University in
   Prague. The template defines all thesis mandatory structural elements and
   typesets their content to fulfil the university formal rules.

   This is version 2 of this template which implements the Technika font
   recommended by CTU graphics identity reference since 2016.
}
\abstractCZ {
    Abstrakt stručně a přesně
    reprezentuje obsah práce, shrnuje cíl, metody, výsledky a závěry. 
}           % If your language is Slovak use \abstractSK instead \abstractCZ

\keywordsEN {%
   document design template; bachelor, master, Ph.D. thesis; \TeX{}.
}
\keywordsCZ {%
    Klíčová slova jsou odborné termíny vyjadřující obsah práce. 
}
\thanks {           % Use main language here
   Chtěl bych poděkovat své manželce Ludmile za podporu nejen finanční.
   Díky tomu mohu na svém pracovišti dělat, co mě baví, a nejsem stresován 
   výplatní páskou.
}
\declaration {      % Use main language here
   Prohlašuji, že jsem předloženou práci vypracoval
   samostatně a že jsem uvedl veškeré použité informační zdroje v~souladu
   s~Metodickým pokynem o~dodržování etických principů při přípravě
   vysokoškolských závěrečných prací.

   V Praze dne 13. 13. 2013 % !!! Attention, you have to change this item.
   \signature % makes dots
}

%%%%% <--   % The place for your own macros is here.

%\draft     % Uncomment this if the version of your document is working only.
%\linespacing=1.7  % uncomment this if you need more spaces between lines
                   % Warning: this works only when \draft is activated!
%\savetoner        % Turns off the lightBlue backround of tables and
                   % verbatims, only for \draft version.
%\blackwhite       % Use this if you need really Black+White thesis.
%\onesideprinting  % Use this if you really don't use duplex printing. 

\makefront  % Mandatory command. Makes title page, acknowledgment, contents etc.


\chap Introduction

\sec Motivation

%Tady napisu, ze plno existuje rada situaci, kdy musime optimalizovat black box.
%K tomuto se hodi evolucni algoritmy, jednim z nejlepsich v real-value domene je DE.
%DE ma nevyhodu, ze nedokaze rozlisit zavislosti mezi castmi promennych a tedy nepracuje
%efektivne. Cilem je adaptovat standrardni DE, aby dokazala rozeznat zavislosti a
%pristusobit to, jakym zpusobem pracuje tomu, jak je to zavisle.

Striving for the best solution of a certain problem is an important part of many fields
of human interest. The process of finding the best solution according to some
criteria is called optimization. Optimization in mathematical notation:

In the real world, there are a large number of
engineering optimization problems whose input-output relationships are noisy and
indistinct, so it cannot be assumed anything about the optimized function but it's
possible to observe its outputs on given inputs. In these cases, the function is 
called a black box function and an optimization as a black box optimization.

Due to these limited capabilities, all black box optimization algorithms are
allowed to perform just these three steps:

\begitems
*Create a candidate solution
*Check if a candidate is feasible or not
*Evaluate its fitness by using the objective function
\enditems

From the mid-1950s, a new family of optimization algorithms called Evolutionary
algorithms has started to be developed.~\cite[Friedberg1958ALM,Friedberg1959ALM]
Evolutionary algorithms have proven to be very effective while optimizing black
box functions.~\cite[comparison] Among evolutionary algorithms, \em Differential
Evolution \em (DE) has achieved excellent results on real-valued black box functions.~\cite[DE].

However, there exists a class of functions containing dependent solution components
and the recognition of those components may be a crucial task which could lead to
significantly enhanced performance. Nevertheless, DE does not provide any tool capable of
recognizing the dependent components of a solution. Thus it can be seen that this particular
class of functions is the weakness of DE.

This work aims to find a way how to find dependencies between parts of solutions and
how to represent a dependency structure. It would lead to the proposal of a new crossover
operator for DE well suited for functions with dependent solution components. This new 
operator should partially eliminate the above-mentioned weakness of DE.



\chap Evolutionary algorithms

This chapter is mainly based on these references:~\cite[IntoEA, wong2015evolutionary, Luke2009]

Evolutionary algorithms (EAs) is a set of stochastic metaheuristic optimization algorithms
inspired by Darvin's theory of evolution by natural selection.~\cite[Darwin] The theory
describes the process of development of organisms over time as a result of changes
in heritable traits. Changes which allow an organism to better adapt to its environment
will help it survive and reproduce more offspring. This phenomenon is commonly
called as “Survival of the fittest” first used by Herbert Spencer.~\cite[Spencer]

In analogy, EA maintains a “population” of potential solutions (\em individuals\em) for the
given problem. Population is iteratively evolved by encouraging the reproduction of
fitter individuals. The fitness is usually the value of the objective function in the
optimization problem being solved. New candidate solutions are created either by
combining existing individuals (crossover) or by modification of an individual (mutation).
The algorithm runs until a candidate solution with sufficient quality is found
or a user-defined computational limit is reached.


\sec Components of evolutionary algorithms

In this section, certain parts of evolutionary algorithms are discussed in detail.
In general, EAs can be divided into various components, procedures, or operators,
which are:

\begitems
*representation of individuals
*objective function
*population
*parent selection
*crossover operator
*mutation operator
*replacement strategy
\enditems

To define a particular EA, it is necessary to specify these components. In addition,
the initialization procedure and the termination condition must be defined to obtain working
algorithm.

\secc Representation of individuals

Each individual is encoded in so called \em chromosomes\em. Representation of chromosome is
called \em genotype \em. While \em phenotype \em refers to the interpretation of the genotype,
in other words, how the objective function treats the genotype. The Representation also involves
a genotype-phenotype mapping. For instance, given an optimization problem on integers, if one
decide to represent them by their binary code, then $20$ would be seen as a phenotype 
and $10100$ as a genotype representing it.

\bigskip

\medskip
\picw=15.3cm \cinspic g-pmapping.png
\bigskip
\caption/f Examples of genotype-phenotype mapping
(a) Integere representation
(b) Protein structure representation on a lattice model
(c) Tree representation for a mathematical expression~\cite[wong2015evolutionary]
\medskip

\secc Objective function

The role of the objective function, is to represent the requirement to adapt to.
Objective function defines how quality individual is with respect to the problem
in consideration. Technically, it is a function which takes an individual as an input
and produces a the measure of quality of a given individual as an output. The measure of
quality is called \em fitness \em and the objective function is called \em fitness
function\em.

To remain with the above-mentioned example, the problem was to minimise $x^2$ on
integers. The fitness of the individual represented by the genotype $10100$ would be
defined as a square of its corresponding phenotype: $20^2 = 400$

\secc Population

Population in a evolutionary algorithm means a set of individuals. Population can be
specified only by setting the population size, in other words, how many individuals
are in population. This parameter is usually specified by user.

\secc Parent selection

During each \em generation \em (one iteration of algorithm), a certain part of population
is selected to breed offspring. 
The choice is made similarly to natural selection, in other words, fitter individuals
are preferred, nevertheless, low quality individuals are given a small, but positive change
to be selected. Otherwise, the EA could become too greedy and get stuck in the local optimum.
Parent selection along with the replacement strategy pushes quality improvements.
Parent selection as well as other EA procedures are usually stochastic.

Individuals selected by parent selection are called \em parents\em.

\secc Crossover operator

\em Crossover \em is a genetic operator used to combine typically two parents to
generate new offsprings. The idea behind crossover is that by mating two
individuals with different but desirable features, it is possible to produce offsprings
which combines both of those features. Similarly to other genetic operators, crossover is stochastic.

\medskip
\picw=15.3cm \cinspic crossover.png
\medskip
\caption/f Example of One-point crossover (part of chromosome right to the Crossover point
are swapped between two parents chromosomes)~\cite[crossoverpic]
\medskip


\secc Mutation operator

\em Mutation \em is an unary genetic operator which changes parts of the chromosome of an
individual, typically randomly. In mutation, the mutated individual may change entirely from
the original individual. Mutation is used to maintain and introduce diversity in the
genetic population.

\medskip
\picw=8cm \cinspic mutation.png
\medskip
\caption/f Example of mutation~\cite[mutationpic]
\medskip

\secc Replacement strategy

\em Replacement strategy \em defines which individuals survive and become members of
subsequent generation. Typically, the decision is based on the quality of individuals,
prefering those with higher fitness. The replacement strategy is similar to parent
selection, as both are responsible for promoting quality improvement. However,
parent selection is usually stochastic while the replacement strategy is often
deterministic.


\secc Initialization

It generates a defined number of individuals of the given representation, thereby
creating the initial population. \em Initialization \em is often done randomly
due to lack of knowledge when optimizing black box functions.


\secc Termination condition

The algorithm runs until the \em termination condition \em has been reached. If we
know the optimum of the optimized problem, then reaching the optimum (with a given
precision $\epsilon \geq  0$) is a natural termination condition. However, since EAs
are stochastic, there is usually no guarantee to reach an optimum and the condition
would be never satisfied. Therefore, this condition is extended to a condition which
certainly stops the algorithm, such as the limited number of fitness function calls.


\sec General scheme

%By merging all above-mentioned components, the evolutionary algorithm is formed.
%It this section
%irstly, an initial population is generated by initialization procedure.
In the previous section, the main parts of an EA were introduced individually.
By merging all above-mentioned components, the evolutionary algorithm is formed.
This section describes the way an EA works as a whole.
\bigskip

%\medskip
\picw=14cm \cinspic EApseudocode.jpg
\medskip
\caption/f General scheme of an evolutionary algorithm
%\medskip

\bigskip

Firstly, an initial population is generated by an initialization procedure.
The population is subsequently evaluated by a fitness function. Then starts
a generational process.

The generational process is repeated until a terminal
condition is not satisfied. Generational process starts by parent selection, usually
based on a fitness, some individuals are chosen to seed the new generation. The
chosen individuals are combined by a crossover operator to produce offsprings, which
are then modified by the mutation operator. Offspring are then evaluated by a fitness
function and the generational process ends by creating a new population. Creating a new
population is performed with respect to the replacement strategy that selects some newly
created offsprings to replace some members of the old population.

The algorithm returns the best individual found so far, eventually some statistics concerning
the run of algorithm.

\sec Differential evolution

This chapter is mainly based on these references:~\cite[DE, Luke2009]

Differential evolution was introduced by Storn and Price~\cite[DE] as an efficient
evolutionary algorithm initially designed for multidimensional real-valued spaces.

DE utilizes a population of real vectors. The initial population is chosen randomly.
After initialization, for each member $\vec{x}_i$ of a population $P$ is generated a
so called \em mutatant vector\em. A mutatant vector is generated by adding the
weighted difference between two individuals ($\vec{x}_{r_2}$, $\vec{x}_{r_3}$) to a third individual
($\vec{x}_{r_1}$). These three individuals are mutually exlusive. The mutant vector is then
crossed over with $\vec{x}_i$ 
The offspring $\vec{o}_i$ is then created by crossing over the mutatnt vector with $\vec{x}_i$.

Note that a size of mutatant vector is largely based on the actual variance in the
population. The mutant vector will make major changes if the population is spread, on
the other hand mutant vecotr will be small if the population is condensed in a
particular region. Thus DE belongs to the family of adaptive mutation algorithms.

Lastly, newly created offspring is compared to his parent using the greedy criteria.
If the offspring is better, it replace its parent in the population.

To put it more formally, standard DE is defined by specifying of following components of EA:


\secc Representation

Individuals are represented by real-valued vectors:
$$
\vec{x_i} = \{x_{i,0}, x_{i,1}, ..., x_{i,D-1}\},
\forall{j}: x_{i,j} \in{\bbchar{R}},
$$
\noindent where \em i \em represents the index of the individual in the population \em P \em
and \em D \em stands for dimension of the optimized function. Population is represented as
following:
$$
P = \{\vec{x}_0, \vec{x}_0, ..., \vec{x}_{NP-1}\},NP \geq 4,
$$
\noindent where \em NP \em is the size of population.


\secc Mutation

For each individual in the population $\vec{x}_i, i = 0, 1, ..., NP-1$, DE generates mutant
vector $\vec{m}_i$ as following:
$$
\vec{m}_i = \vec{x}_{r_1} + F*(\vec{x}_{r_2} - \vec{x}_{r_3})
$$
%\medskip
%\centerline{$\vec{m}_i = \vec{x}_{r_1} + F*(\vec{x}_{r_2} - \vec{x}_{r_3})$,}
%\medskip
\noindent with random, mutually exclusive indexes $r_1, r_2, r_3 \in\{0, 1, ..., NP-1\}$,
which are also chosen to be different from the running index \em i\em. $F$, called 
\em differential weight\em, is a constant factor $\in [0, 2]$, representing the
amplification of the random deviation $(\vec{x}_{r_2} - \vec{x}_{r_3})$. 

\secc Crossover

After mutation the mutant vector $\vec{m}_i$ undergoes a crossover with the its relevant
individual $\vec{x}_i$ to generate the offspring $\vec{o}_i$. Standard DE us binomial
crossover, where offspring is generated as following:
$$
f(x) = \cases{ -1 & for $x\ge 0$,\cr
0 & otherwise.} \eqmark
$$
%\medskip
%\centerline{$\vec{o}_i = \vec{x}_{r_1} + F*(\vec{x}_{r_2} - \vec{x}_{r_3})$......,}
%\medskip
\noindent where: \em description of symbols ....\em $\vec{x}_i$ is the parent of $\vec{o}_i$.
Therefore, it can be seen that each individual from the population generates offspring. In
other words, the parent selection chooses all individuals from the population.

The probability of crossover is signed as $CR$.


\secc Replacement strategy

To decide which individuals become members of subsequent generation, DE compares offspring
$\vec{o}_i$ to its relevant parent $\vec{x}_i$ using the greedy criteria. Thus, if $\vec{o}_i$
is better than $\vec{x}_i$, the offspring $\vec{o}_i$ will replace the parent $\vec{x}_i$ and
enter the population of the next generation. To put it more formally, new population is determined
as follows:

$$
P = \{\vec{p}_i |  \vec{p}_i = argmax(\vec{x}_i, \vec{o}_i); i = 0,1,...,NP-1\}
$$

%\medskip
%\centerline{$P = \{\vec{p}_i |  \vec{p}_i = argmax(\vec{x}_i, \vec{o}_i); i = 1,2,...,NP\}$,}
%\medskip


\bigskip

%\medskip
\picw=14cm \cinspic DEpseudocode.jpg
\medskip
\caption/f General scheme of the differential evolution
%\medskip

\bigskip

%\medskip
\picw=14cm \cinspic provisional.jpg
\medskip
\caption/f DE recombination
%\medskip

\bigskip



\chap Linkage information modeling

It is worth nothing, that DE, as was described in previous chapter, uses random, uniform
crossover. The crossover has no assumptions about the structure of optimized function,
specially DE do not take possible dependencies between specific parts of solution into account.

However, there exists a whole class of problems with dependent solution components. De
using uniform crossover not only take posible dependencies into consideration, but even
very often disrupts linkage between strongly connected components. Therefore it can be seen
that mentioned class is a significant weakness of standard DE.

The aim of this work is to propose new crossover operator capable of finding dependencies
and taking them into account when generating new offspring. This chapter proposes two
possible representations of dependency structure and how to adapt crossover operator.

\sec Family Of Subsets

Both representations od dependency structure are based on the \em Family Of Subsets \em
(FOS).~\cite[FOS] FOS is a way how to model linkage information that describe presumed
dependencies between variables. FOS $\cal F = \{$$\cal F$$_1, $ $\cal F$$_2$$, ...\}$ 
represents a subset of powerset $\cal{P(I)}$ of $\cal{I}$, where $\cal{I}$$ =
\{1, 2, ..., d-1\}$ stands fos a set of indices and \em d \em is a number of problem
variables (dimension of the fitness function). Each block $\cal F$$_j \in$ $\cal F$
contains the indices of those variables that are considered dependent. The block $\cal F$$_j$
divides the set of all variables into two mutually exclusive subsets of variables $\cal F$$_j$ and
$\cal F$ $\setminus$ $\cal F$$_j$. Variable within those subsets are crossed over together.~\cite[FOS]

To put it more formally, within crossover for each individual $\vec{x}_i$ each block
$\cal F$$_j$ is iteratively considered in random order. For each block $\cal F$$_j$ is
randomly generated new mutant vector $\vec{m}_i$ in the same way as standard mutation.
If the mutants values for variables contained in $\cal F$$_j$ are different from those
in parent $\vec{x}_i$, then these value are overwritten in the parent $\vec{x}_i$, this
produces $\vec{x}_{i,new}$ which is then evaluated by the fitness function. New individual
$\vec{x}_{i, new}$ is only accented if it has better or equal fitness value than the
original $\vec{x}_i$. How the DE changes is captured in the figure~\ref[DEFOSpseudocode].

%\bigskip

%\medskip
%\picw=14cm \cinspic DEFOSpseudocode.jpg
%\medskip
%\caption/f Pseudocode of DE with adjusted crossover when FOS is known
%\medskip

%\bigskip


\sec Linkage tree

There exist many FOS structures and any of them can be used to model linkage structure,
however this work focus on two of them. First of them is \em linkage tree \em (LT-FOS).

‘‘\em The Linkage Tree is the hierarchical cluster tree of the problem variables using
an agglomerative hierarchical clustering algorithm with a distance measure $\cal M$.
The distance measure $\cal M$$(X_1, X_2)$ measures the degree of dependency between
two sets of variables $X_1$ and $X_2$.\em’’~\cite[LT]

There exist more potential distance measures $\cal M$$(X_1, X_2)$, however, in this work,
two distance measures are used. They are described in detail in following chapter~\ref[ch4].

The linkage tree is a tree with $D$ leaf nodes and $D-1$ inner nodes, where $D$ is number
of problem variables. Each node of the LT-FOS represents certain block of variables $\cal F$$_j$.
The key property of the LT-FOS is that each $\cal F$$_j$ which containts more than one variable
is the union of two other sets $\cal F$$_k$, $\cal F$$_l \in $$\cal F$, where $j \neq k \neq l$
(transitively). To put it more formally, for any subset $\cal F$$_i$, where $|\cal F$$_j| > 1$,
there exist subsets $\cal F$$_k, \cal F$$_l$ for which the following applies:

\begitems
\style N
*$\cal F$$_k, \cal F$$_l \neq \emptyset$
*$\cal F$$_k \cap \cal F$$_l = \emptyset$
*$\cal F$$_k \cup \cal F$$_l$ = $\cal F$$_j$
\enditems

The hierarchical clustering procedure starts by assigning each problem variable to a separate
block in random order. The procedu proccedes bottom-up, therefore the tree is initialized with
these univariete blocks as leaves. In each step new node is created by merging two nodes of the
tree which were determined, by given distance measure $\cal D$, as the most dependent. It is
important to mention that each node can be merged only once. The process of merging stops
when no more merges are possible to put it another way, root node has been created.
Due to the way the procedure works, root node has to be a set of all problem variables.
The tree itself contains multiple levels of dependencies. From univariate level at a height of
zero to complete dependency between all variables at a depth of zero.~\cite[LT]

\medskip
\picw=10cm \cinspic LT.png
\medskip
\caption/f Example Linkage tree~\cite[LTpic]
\medskip


The \em DE using the LT FOS structure \em (LT-FOS DE) build the LT-FOS in every generation. 
Once the tree is built, LT-FOS DE traverses the tree in the opposite order of the merging.

\sec Marginal product

Second introduced FOS structure is \em marginal product \em (MP-FOS)~\cite[MP]. The MP-FOS is
defined as set $\cal F$, where for each $\cal F$$_k, \cal F$$_l \in \cal F$ holds that
$\cal F$$_k \cap \cal F$$_l = \emptyset$. When all variables are independent, MP-FOS is called
univariate FOS and $\cal F$$ = \{\{0\}, \{1\}, ... , \{D-1\}\}$, where $D$ is number of problem
variables. On the contrary, when all variables are considered dependent, MP-FOS is called compact
FOS.

Before introduction of the \em MP-FOS building procedure \em it is necessary to define
\em strength of block \em $\cal S_{M}$$(\cal F$$_j)$ which determines dependency rate
within certain block $\cal F$$_j$ according to given distance measure $\cal M$. The strength of
block is defined as following:

$$
{\cal S_M}({\cal F}_i) = \cases{ {C \over D-1} \sum_{v \in {\cal I}} {\cal M}({\cal F}_i,
\{v\}) & if $|{\cal F}_i| = 1$,\cr
{1 \over |{\cal F}_i| (|{\cal F}_i|-1)} \sum_{u \in {\cal F}_i} \sum_{v \in {\cal F}_i}
{\cal M}(\{u\}, \{v\}) & otherwise,} \eqmark
$$


\noindent where $C \geq 0$ is user selected factor defining the degree of strength of 
univariete blocks.

The MP-FOS building procedures starts by initializing MP-FOS $\cal F$ as univariete FOS and by
assigning the strength of block to each block. In each step new block $\cal F$$_n$ is created
by merging two blocks ${\cal F}_a, {\cal F}_b \in \cal F$, which are determined, by given
distance measure $\cal M$, as the most dependent. Then, $\cal F$$_n$ is assigned its strength
of block. If newly created block meets the following conditions:

\begitems
\style N
*${\cal S_M}({\cal F}_n) \geq \theta_1, \theta_1 \in{\bbchar{R}}$
*${\cal S_M}({\cal F}_n) \geq K max({\cal S_M}({\cal F}_a), {\cal S_M}({\cal F}_b))$,
*$|{\cal F}_n| \leq \theta_2, \theta_2 \in{\bbchar{N}}$,
\enditems

\noindent where thresholds $\theta_1$ and $\theta_2$ are defined by user, usually chosen as
$\theta_1 > 0$ and $\theta_2 < D$. Then $\cal F$$_n$ is inserted to the FOS $\cal F$ and $\cal F$$_a, \cal F$$_b$ are
removed from $\cal F$. The procedure runs until a newly created block $\cal F$$_n$ has not
met mentioned conditions or until MP-FOS has became the compact FOS.

The \em DE using the MP FOS structure \em (MP-FOS DE) build the MP-FOS in every generation.
After building the MP-FOS, MP-FOS DE traverses FOS in the opposite order of the merging, in
other words, from the last one added to FOS to the first one.


\medskip
\label[DEFOSpseudocode]
\picw=14cm \cinspic DEFOSpseudocode.jpg
\medskip
\caption/f provisional pseudocode
\medskip

\label[ch4] \chap Identification of the linkage structure

In previous chapter two possible representations of dependency structure were introduced.
In order to represent the dependency structure, it is necessary to determine the degree
of dependence between each pair of variables and furthermore between each pair of sets of
variables. The tool used to measure the degree is called the distance measure and is
denoted as $\cal M$.

Formally, $\cal M$ is a function that takes two sets of variables as input and produces a
real, positive number as output. $\cal M$ is defined as follows~\cite[LT]:

$$
{\cal M}(X_i, X_j) = {1 \over |X_i| |X_j|} \sum_{u \in X_i} \sum_{v \in X_j}
n_{u, v} \eqmark
$$

\noindent where $X_i$ and $X_j$ are sets of variables and $n_{u, v}$ is element of the
\em dependency matrix \em $\cal N$ at position $u,v$.

The dependency matrix 

$$
%{\cal N} = \pmatrix{ a & b & \dot \cr c & d & \dot}
{\cal N} = \pmatrix{n_{0,0} & n_{0,1} & \dots & \dots & n_{0, D-1} \cr 
n_{1,0} & n_{1,1} & & & \vdots \cr
\vdots & & \ddots &  & \vdots \cr
\vdots & &  & \ddots & \vdots \cr
n_{D-1, 0} & \dots & \dots & \dots & n_{D-1, D-1}} \in {\bbchar R}^{D \times D}
$$

\noindent is a symetric and positive semi-definite matrix.
The dependency matrix gives the dependency between each pair of variables specifically,
the element $n_{i, j}$ denotes he pairwise dependency strength between i-th and j-th
problem variables. Consequently $\cal N$ contains zeros on diagonal i.e. $\forall i =
0, 1, ..., D-1 : n_{i, i} = 0$.

There are several methods how to contruct the dependency matrix $\cal N$ nevertheless,
this work focus only on two of them.

\sec Fitness-based method

The first method called \em non-linearity check \em (NC) is to define whether two
variables interact is directly based on fitness values. The method works under
the assumption that non-linear interactions may exist only between dependent
variables. Specially, it classify a pair of variables either separable or non-separable
by comparing the difference in overall fitness while making the exact same change for
a certain pair of chromosome of given individual $x_{i, j}$ for different values of
$x_{i, k}, k \neq j$.~\cite[LINC, LIMD] Nevertheless, checking only one individual
is not convincing enough, because there may exist linearity between a dependent pair
of variables in some context, therefore more individuals must be checked. In this work,
$m$ best individuals from the population are checked, where $m = max\{2, {3 \over 20}NP\}$.
$C$ denotes the set of indices of $m$ best individuals in population.

For each of chosen individuals $\vec{x}_i, i \in C$ and for each pair of variables $j$, $k$
a pairwise dependency $d_{i,j,k}$ is calculated. The overall pairwise dependency between
those variables is determined by aggregating those values as following:

$$
n_{j, k} = {1 \over m} \sum_{i \in C} d_{i,j,k}.
$$

In order to calculate $d_{i,j,k}$, four individuals are picked by combining all possible
points that can be created by picking two different values for each $x_{i,j}$ and
$x_{i,k}$.~\cite[MAIN] The absolute value of differences in overall fitness value
for those point are used to calculate the potential dependence between \em j-th \em and
\em k-th \em variables by determining whether the adjustment to $x_{i,k}$ affect the change
in fitness caused by modification to $x_{i,j}$. Define:

$$
\Delta_{i, j} = |(f(\vec{x}_i) | x_{i, j} = a_j, x_{i, k} = a_k) - (f(\vec{x}_{i}) |
x_{i, j} = a_j + b_j, x_{i, k} = a_k)|,
$$
$$
\Delta_{i, j,k} = |(f(\vec{x}_i) | x_{i, j} = a_j, x_{i, }k = a_k + b_k) -
(f(\vec{x}_i) | x_{i, j} = a_j + b_j, x_{i, k} = a_k + b_k)|, 
$$

\noindent where $f$ denotes fitness function, $a_j, a_k, b_j, b_k$ can be any real value,
such that for every variable $j, a_{j}$ and $a_{j} + b_{j}$ remains within the bound
for $x_{i,j}$ inside the current population, to put it more formally:

$$
\forall j :\max_{\vec{x}_i \in P}(x_{i,j}) \geq a_j \geq \min_{\vec{x}_i \in P}(x_{i,j}),
$$

$$
\forall j :\max_{\vec{x}_i \in P}(x_{i,j}) \geq a_j+b_j \geq \min_{\vec{x}_i \in P}(x_{i,j}),
$$

\noindent nevertheless, in this work are used values that have been empirically found
for~\cite[MAIN], which are

$$
a_j = \min_{\vec{x}_i \in P}(x_{i, j}) + (\max_{\vec{x}_i \in P}(x_{i, j}) -
\min_{\vec{x}_i \in P}(x_{i, j})) * 0.35,
$$

$$
b_j = (\max_{\vec{x}_i \in P}(x_{i, j}) - \min_{\vec{x}_i \in P}(x_{i, j})) * 0.35.
$$

Finally, \em j-th \em and \em k-rh \em are said to dependent when $|\Delta_{i,j} - \Delta_{i, j,k}|
\geq 0$, the pairwise dependent $d_{i,j,k}$ is defined as:

$$
d_{i,j,k} = \cases{1 - {\Delta_{i,j,k} \over \Delta_{i,j}} & if $\Delta_{i,j} \geq \Delta_{i,j,k}$,
\cr 1 - {\Delta_{i,j} \over \Delta_{i,j, k}} & otherwise.} \eqmark
$$

\noindent note that $d_{i,j,k}$ as well as $n_{j,k}$ lie within $[0, 1)$ with $0$ indicating
independent variables.


\sec Distribution-based mathod
The second method to construct the dependency matrix $\cal N$ is called 

%\chap Setup

%\chap Results

\bibchap
\usebib/c (simple) myreferences


\bye