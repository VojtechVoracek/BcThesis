% The documentation of the usage of CTUstyle -- the template for
% typessetting thesis by plain\TeX at CTU in Prague
% ---------------------------------------------------------------------
% Petr Olsak  Jan. 2013

% You can copy this file to your own file and do some changes.
% Then you can run:  pdfcsplain your-file
\input ctustyle2  % The template (in version 2) is included here.
%\input pdfuni    % Uncomment this if you need accented PDFoutlines
\input opmac-bib % Uncomment this for direct reading of .bib database files 
%\input my_references.bib



\worktype [B/EN]
\faculty {F3}
\department {Department of Cybernetics}
\title {Differential Evolution Crossover with Dependency Detection}
\titleCZ {Křížení pro diferenciální evoluci s detekcí závislostí}
\author {Vojtěch Voráček}
\date {May 2021}
\supervisor {Ing. Petr Pošík, Ph.D.}


\pagetwo    {
   \picw=18.3cm 
   \cinspic zadani.png
}  % The text printed on the page 2 at the bottom.


\abstractCZ {
    Diferenciální evoluce je považována za jeden z nejlepších evolučních algoritmů
    pro spojité black-box optimalizační problémy. Originální verze diferenciální evoluce
    použí náhodný uniformí operátor křížení, který nebere v potaz potencialní závislosti
    mezi částmi řešení a může tyto vazby narušovat.

    \medskip

    Cílem této práce je poskytnout nový operátor křížení pro diferenciální evoluci,
    který bude vhodnější pro třídu problémů obsahující závislé komponenty řešení.

    \medskip

    V této práci jsou prezentovány dvě možnosti, jak nalézt závislosti mezi proměnnými
    problému a dvě možnosti, jak modelovat strukturu vazeb. S užitím těhto metod byly
    navženy čtyři nové operátory křížení.

    \medskip

    Nově navržené algoritmy jsou vyhodnoceny na množině referenčních funkcí a jsou
    porovnány s dalšími optimalizačními algoritmy, včetně original diferenciální evoluce.

    \medskip

    Výsledky ukazují, že nově navžené algoritmy dosahují výrazně lepšího výkonu a
    škálovatelnosti než originální diferenciální evoluce ve smyslu potřebného počtu
    vyhodnocení účelové funkce k nalezení globálního optima. Něktére z nich podobné
    škálovatelnosti jako CMA-ES, jeden z nejmodernějších evolučních algoritmů.

    \medskip

}           % If your language is Slovak use \abstractSK instead \abstractCZ

\abstractEN {
   The differential evolution is considered as one of the best evolutionary
   algorithms for continuous black-box optimization problems. The original version of
   differential evolution uses random uniform crossover operator which do not take
   possible dependencies between parts of solution into account and may disrupts
   these linkages.

   \medskip
   The goal of this work is to propose new a crossover operator for differential
   evolution more suitable for the class of problems containing dependent solution components
   of a solution.

   \medskip

   In this work are presented two options to find dependencies between problem variables
   and two possibilities to model the linkage structure. Finally, with use of those methods
   four new crossover operators are designed.

   \medskip

   Newly proposed algorithms are evaluated on a set of benchmark functions and compared
   with other optimization algorithms including the original differential evolution.

   \medskip

   The results show that all newly proposed algorithms achieve significantly better performace
   and scalability than original differential evolution in terms of fitness function
   evaluations needed to find a global optimum. Some of them achieve comparable scalability
   to state-of-the-art evolutionary algorithm CMA-ES.

   \medskip
}


\keywordsEN {%
   Evolutionary algorithm, differential evolution, linkage tree, marginal product,
   non-linearity check, maximal information coefficient, linkage learning.
}
\keywordsCZ {%
    Evoluční algoritmus, diferenciální evoluce, vazebný strom, mezní produkt,
    kontrola nelinearity, maximální informační koeficient, učení se závislostí. 
}
\thanks {           % Use main language here
   First of all, I would like to express my gratitude to my supervisor Ing. Petr
   Pošík, Ph.D. for his guidance, his helpful comments, and his patience with me.
   \smallskip
   \rightline{Thank you!}
   \smallskip
   Many thanks belong also to my family, current and future, and to all my friends
   for their support.
   \smallskip
   \rightline{Love you!}
}
\declaration {      % Use main language here
   I declare that the presented work was developed independently and that I have
   listed all sources of information used
   within it in accordance with the methodical instructions for observing the ethical
   principles in the preparation of university
   theses.
   \smallskip
   Prague, 20. May 2020 % !!! Attention, you have to change this item.
   \signature % makes dots
}

%%%%% <--   % The place for your own macros is here.

%\draft     % Uncomment this if the version of your document is working only.
%\linespacing=1.7  % uncomment this if you need more spaces between lines
                   % Warning: this works only when \draft is activated!
%\savetoner        % Turns off the lightBlue backround of tables and
                   % verbatims, only for \draft version.
%\blackwhite       % Use this if you need really Black+White thesis.
%\onesideprinting  % Use this if you really don't use duplex printing. 

\makefront  % Mandatory command. Makes title page, acknowledgment, contents etc.


\chap Introduction

\sec Motivation

%Tady napisu, ze plno existuje rada situaci, kdy musime optimalizovat black box.
%K tomuto se hodi evolucni algoritmy, jednim z nejlepsich v real-value domene je DE.
%DE ma nevyhodu, ze nedokaze rozlisit zavislosti mezi castmi promennych a tedy nepracuje
%efektivne. Cilem je adaptovat standrardni DE, aby dokazala rozeznat zavislosti a
%pristusobit to, jakym zpusobem pracuje tomu, jak je to zavisle.

Striving for the best solution of a certain problem is an important part of many fields
of human interest. The process of finding the best solution according to some
criteria is called optimization. Optimization in mathematical notation:

In the real world, there are a large number of
engineering optimization problems whose input-output relationships are noisy and
indistinct, so it cannot be assumed anything about the optimized function but it's
possible to observe its outputs on given inputs. In these cases, the function is 
called a black box function and an optimization as a black box optimization.

Due to these limited capabilities, all black box optimization algorithms are
allowed to perform just these three steps:

\begitems
*Create a candidate solution
*Check if a candidate is feasible or not
*Evaluate its fitness by using the objective function
\enditems

From the mid-1950s, a new family of optimization algorithms called Evolutionary
algorithms has started to be developed.~\cite[Friedberg1958ALM,Friedberg1959ALM]
Evolutionary algorithms have proven to be very effective while optimizing black
box functions.~\cite[comparison] Among evolutionary algorithms, \em Differential
Evolution \em (DE) has achieved excellent results on real-valued black box functions.~\cite[DE].

However, there exists a class of functions containing dependent solution components
and the recognition of those components may be a crucial task which could lead to
significantly enhanced performance. Nevertheless, DE does not provide any tool capable of
recognizing the dependent components of a solution. Thus it can be seen that this particular
class of functions is the weakness of DE.

This work aims to find a way how to find dependencies between parts of solutions and
how to represent a dependency structure. It would lead to the proposal of a new crossover
operator for DE well suited for functions with dependent solution components. This new 
operator should partially eliminate the above-mentioned weakness of DE.



\chap Evolutionary algorithms

This chapter is mainly based on these references:~\cite[IntoEA, wong2015evolutionary, Luke2009]

Evolutionary algorithms (EAs) is a set of stochastic metaheuristic optimization algorithms
inspired by Darvin's theory of evolution by natural selection.~\cite[Darwin] The theory
describes the process of development of organisms over time as a result of changes
in heritable traits. Changes which allow an organism to better adapt to its environment
will help it survive and reproduce more offspring. This phenomenon is commonly
called as “Survival of the fittest” “takto” first used by Herbert Spencer.~\cite[Spencer]

In analogy, EA maintains a “population” of potential solutions (\em individuals\em) for the
given problem. Population is iteratively evolved by encouraging the reproduction of
fitter individuals. The fitness is usually the value of the objective function in the
optimization problem being solved. New candidate solutions are created either by
combining existing individuals (crossover) or by modification of an individual (mutation).
The algorithm runs until a candidate solution with sufficient quality is found
or a user-defined computational limit is reached.


\sec Components of evolutionary algorithms

In this section, certain parts of evolutionary algorithms are discussed in detail.
In general, EAs can be divided into various components, procedures, or operators,
which are:

\begitems
*representation of individuals
*objective function
*population
*parent selection
*crossover operator
*mutation operator
*replacement strategy
\enditems

To define a particular EA, it is necessary to specify these components. In addition,
the initialization procedure and the termination condition must be defined to obtain working
algorithm.

\secc Representation of individuals

Each individual is encoded in so called \em chromosomes\em. Representation of chromosome is
called \em genotype \em. While \em phenotype \em refers to the interpretation of the genotype,
in other words, how the objective function treats the genotype. The Representation also involves
a genotype-phenotype mapping. For instance, given an optimization problem on integers, if one
decide to represent them by their binary code, then $20$ would be seen as a phenotype 
and $10100$ as a genotype representing it.

\secc Objective function

The role of the objective function, is to represent the requirement to adapt to.
Objective function defines how quality individual is with respect to the problem
in consideration. Technically, it is a function which takes an individual as an input
and produces a the measure of quality of a given individual as an output. The measure of
quality is called \em fitness \em and the objective function is called \em fitness
function\em.

To remain with the above-mentioned example, the problem was to minimise $x^2$ on
integers. The fitness of the individual represented by the genotype $10100$ would be
defined as a square of its corresponding phenotype: $20^2 = 400$

\secc Population

Population in a evolutionary algorithm means a set of individuals. Population can be
specified only by setting the population size, in other words, how many individuals
are in population. This parameter is usually specified by user.

\secc Parent selection

During each \em generation \em (one iteration of algorithm), a certain part of population
is selected to breed offspring. 
The choice is made similarly to natural selection, in other words, fitter individuals
are preferred, nevertheless, low quality individuals are given a small, but positive change
to be selected. Otherwise, the EA could become too greedy and get stuck in the local optimum.
Parent selection along with the replacement strategy pushes quality improvements.
Parent selection as well as other EA procedures are usually stochastic.

Individuals selected by parent selection are called \em parents\em.

\secc Crossover operator

\em Crossover \em is a genetic operator used to combine typically two parents to
generate new offsprings. The idea behind crossover is that by mating two
individuals with different but desirable features, it is possible to produce offsprings
which combines both of those features. Similarly to other genetic operators, crossover is stochastic.

\secc Mutation operator

\em Mutation \em is an unary genetic operator which changes parts of the chromosome of an
individual, typically randomly. In mutation, the mutated individual may change entirely from
the original individual. Mutation is used to maintain and introduce diversity in the
genetic population.

\secc Replacement strategy

\em Replacement strategy \em defines which individuals survive and become members of
subsequent generation. Typically, the decision is based on the quality of individuals,
prefering those with higher fitness. The replacement strategy is similar to parent
selection, as both are responsible for promoting quality improvement. However,
parent selection is usually stochastic while the replacement strategy is often
deterministic.


\secc Initialization

It generates a defined number of individuals of the given representation, thereby
creating the initial population. \em Initialization \em is often done randomly
due to lack of knowledge when optimizing black box functions.


\secc Termination condition

The algorithm runs until the \em termination condition \em has been reached. If we
know the optimum of the optimized problem, then reaching the optimum (with a given
precision $\epsilon \geq  0$) is a natural termination condition. However, since EAs
are stochastic, there is usually no guarantee to reach an optimum and the condition
would be never satisfied. Therefore, this condition is extended to a condition which
certainly stops the algorithm, such as the limited number of fitness function calls.


\sec General scheme

In the previous section, the main parts of an EA were introduced individually.
By merging all above-mentioned components, the evolutionary algorithm is formed.
This section describes the way an EA works as a whole.

\midinsert \clabel[EAPSEUDO]{Evolutionary algorithm pseudocode}
\picw=14cm \cinspic EApseudocode.jpg
\medskip
\caption/f General scheme of an evolutionary algorithm
\endinsert

Firstly, an initial population is generated by an initialization procedure.
The population is subsequently evaluated by a fitness function. Then starts
a generational process.

The generational process is repeated until a terminal
condition is not satisfied. Generational process starts by parent selection, usually
based on a fitness, some individuals are chosen to seed the new generation. The
chosen individuals are combined by a crossover operator to produce offsprings, which
are then modified by the mutation operator. Offspring are then evaluated by a fitness
function and the generational process ends by creating a new population. Creating a new
population is performed with respect to the replacement strategy that selects some newly
created offsprings to replace some members of the old population.

The algorithm returns the best individual found so far, eventually some statistics concerning
the run of algorithm.

\label[s23] \sec Differential evolution

This chapter is mainly based on these references:~\cite[DE, Luke2009]

Differential evolution was introduced by Storn and Price~\cite[DE] as an efficient
evolutionary algorithm initially designed for multidimensional real-valued spaces.

DE utilizes a population of real vectors. The initial population is chosen randomly.
After initialization, for each member $\vec{x}_i$ of a population $P$ is generated a
so called \em mutatant vector\em. A mutatant vector is generated by adding the
weighted difference between two individuals ($\vec{x}_{r_2}$, $\vec{x}_{r_3}$) to a third individual
($\vec{x}_{r_1}$). These three individuals are mutually exlusive. The mutant vector is then
crossed over with $\vec{x}_i$ 
The offspring $\vec{o}_i$ is then created by crossing over the mutatnt vector with $\vec{x}_i$.

Note that a size of mutatant vector is largely based on the actual variance in the
population. The mutant vector will make major changes if the population is spread, on
the other hand mutant vecotr will be small if the population is condensed in a
particular region. Thus DE belongs to the family of adaptive mutation algorithms.

Lastly, newly created offspring is compared to his parent using the greedy criteria.
If the offspring is better, it replace its parent in the population.

To put it more formally, standard DE is defined by specifying of following components of EA:


\secc Representation

Individuals are represented by real-valued vectors:
$$
\vec{x_i} = \{x_{i,0}, x_{i,1}, ..., x_{i,D-1}\},
\forall{j}: x_{i,j} \in{\bbchar{R}},
$$
\noindent where \em i \em represents the index of the individual in the population \em P \em
and \em D \em stands for dimension of the optimized function. Population is represented as
following:
$$
P = \{\vec{x}_0, \vec{x}_0, ..., \vec{x}_{NP-1}\},NP \geq 4,
$$
\noindent where \em NP \em is the size of population.


\secc Mutation

For each individual in the population $\vec{x}_i, i = 0, 1, ..., NP-1$, DE generates mutant
vector $\vec{m}_i$ as following:
$$
\vec{m}_i = \vec{x}_{r_1} + F*(\vec{x}_{r_2} - \vec{x}_{r_3})
$$
%\medskip
%\centerline{$\vec{m}_i = \vec{x}_{r_1} + F*(\vec{x}_{r_2} - \vec{x}_{r_3})$,}
%\medskip
\noindent with random, mutually exclusive indexes $r_1, r_2, r_3 \in\{0, 1, ..., NP-1\}$,
which are also chosen to be different from the running index \em i\em. $F$, called 
\em differential weight\em, is a constant factor $\in [0, 2]$, representing the
amplification of the random deviation $(\vec{x}_{r_2} - \vec{x}_{r_3})$. 

\secc Crossover

After mutation the mutant vector $\vec{m}_i$ undergoes a crossover with the its relevant
individual $\vec{x}_i$ to generate the offspring $\vec{o}_i$. Standard DE us binomial
crossover, where offspring is generated as following:
$$
f(x) = \cases{ -1 & for $x\ge 0$,\cr
0 & otherwise.} \eqmark
$$
%\medskip
%\centerline{$\vec{o}_i = \vec{x}_{r_1} + F*(\vec{x}_{r_2} - \vec{x}_{r_3})$......,}
%\medskip
\noindent where: \em description of symbols ....\em $\vec{x}_i$ is the parent of $\vec{o}_i$.
Therefore, it can be seen that each individual from the population generates offspring. In
other words, the parent selection chooses all individuals from the population.

The probability of crossover is signed as $CR$.


\secc Replacement strategy

To decide which individuals become members of subsequent generation, DE compares offspring
$\vec{o}_i$ to its relevant parent $\vec{x}_i$ using the greedy criteria. Thus, if $\vec{o}_i$
is better than $\vec{x}_i$, the offspring $\vec{o}_i$ will replace the parent $\vec{x}_i$ and
enter the population of the next generation. To put it more formally, new population is determined
as follows:

$$
P = \{\vec{p}_i |  \vec{p}_i = argmax(\vec{x}_i, \vec{o}_i); i = 0,1,...,NP-1\}
$$

\midinsert \clabel[DEPSEUOD]{Differential evolution pseudocode}
\picw=14cm \cinspic DEpseudocode.jpg
\medskip
\caption/f General scheme of the differential evolution
\endinsert

\label[ch3] \chap Linkage information modeling

It is worth nothing, that DE, as was described in previous chapter, uses random, uniform
crossover. The crossover has no assumptions about the structure of optimized function,
specially DE do not take possible dependencies between specific parts of solution into account.

However, there exists a whole class of problems with dependent solution components. De
using uniform crossover not only take posible dependencies into consideration, but even
very often disrupts linkage between strongly connected components. Therefore it can be seen
that mentioned class is a significant weakness of standard DE.

The aim of this work is to propose new crossover operator capable of finding dependencies
and taking them into account when generating new offspring. This chapter proposes two
possible representations of dependency structure and how to adapt crossover operator.

\sec Family Of Subsets

Both representations od dependency structure are based on the \em Family Of Subsets \em
(FOS).~\cite[FOS] FOS is a way how to model linkage information that describe presumed
dependencies between variables. FOS $\cal F = \{$$\cal F$$_1, $ $\cal F$$_2$$, ...\}$ 
represents a subset of powerset $\cal{P(I)}$ of $\cal{I}$, where $\cal{I}$$ =
\{1, 2, ..., d-1\}$ stands fos a set of indices and \em d \em is a number of problem
variables (dimension of the fitness function). Each block $\cal F$$_j \in$ $\cal F$
contains the indices of those variables that are considered dependent. The block $\cal F$$_j$
divides the set of all variables into two mutually exclusive subsets of variables $\cal F$$_j$ and
$\cal F$ $\setminus$ $\cal F$$_j$. Variable within those subsets are crossed over together.~\cite[FOS]

To put it more formally, within crossover for each individual $\vec{x}_i$ each block
$\cal F$$_j$ is iteratively considered in random order (crossover probability CR $= 1$).
For each block $\cal F$$_j$ is randomly generated new mutant vector $\vec{m}_i$ in the
same way as standard mutation. If the mutants values for variables contained in $\cal F$$_j$
are different from those in parent $\vec{x}_i$, then these value are overwritten in the
parent $\vec{x}_i$, this produces $\vec{x}_{i,new}$ which is then evaluated by the fitness
function. New individual $\vec{x}_{i, new}$ is only accented if it has better or equal
fitness value than the original $\vec{x}_i$. How the DE changes is captured in the
figure~\ref[DEFOSpseudocode].


\sec Linkage tree

There exist many FOS structures and any of them can be used to model linkage structure,
however this work focus on two of them. First of them is \em linkage tree \em (LT).

“\em The Linkage Tree is the hierarchical cluster tree of the problem variables using
an agglomerative hierarchical clustering algorithm with a distance measure $\cal M$.
The distance measure $\cal M$$(X_1, X_2)$ measures the degree of dependency between
two sets of variables $X_1$ and $X_2$.\em”~\cite[LT]

There exist more potential distance measures $\cal M$$(X_1, X_2)$, however, in this work,
two distance measures are used. They are described in detail in following chapter~\ref[ch4].

The linkage tree is a tree with $D$ leaf nodes and $D-1$ inner nodes, where $D$ is number
of problem variables. Each node of the LT represents certain block of variables $\cal F$$_j$.
The key property of the LT is that each $\cal F$$_j$ which containts more than one variable
is the union of two other sets $\cal F$$_k$, $\cal F$$_l \in $$\cal F$, where $j \neq k \neq l$
(transitively). To put it more formally, for any subset $\cal F$$_i$, where $|\cal F$$_j| > 1$,
there exist subsets $\cal F$$_k, \cal F$$_l$ for which the following applies:

\begitems
\style N
*$\cal F$$_k, \cal F$$_l \neq \emptyset$
*$\cal F$$_k \cap \cal F$$_l = \emptyset$
*$\cal F$$_k \cup \cal F$$_l$ = $\cal F$$_j$
\enditems

The hierarchical clustering procedure starts by assigning each problem variable to a separate
block in random order. The procedu proccedes bottom-up, therefore the tree is initialized with
these univariete blocks as leaves. In each step new node is created by merging two nodes of the
tree which were determined, by given distance measure $\cal M$, as the most dependent. It is
important to mention that each node can be merged only once. The process of merging stops
when no more merges are possible to put it another way, root node has been created.
Due to the way the procedure works, root node has to be a set of all problem variables.
The tree itself contains multiple levels of dependencies. From univariate level at a height of
zero to complete dependency between all variables at a depth of zero.~\cite[LT]

\midinsert \clabel[LTREE]{Linkage tree}
\picw=10cm \cinspic LT.png
\medskip
\caption/f Example Linkage tree~\cite[LTpic]
\endinsert


The \em DE using the LT structure \em (LT DE) build the LT in every generation. 
Once the tree is built, LT DE traverses the tree in the opposite order of the merging.

\sec Marginal product

Second introduced FOS structure is \em marginal product \em (MP)~\cite[MP]. The MP is
defined as set $\cal F$, where for each $\cal F$$_k, \cal F$$_l \in \cal F$ holds that
$\cal F$$_k \cap \cal F$$_l = \emptyset$. When all variables are independent, MP is called
univariate FOS and $\cal F$$ = \{\{0\}, \{1\}, ... , \{D-1\}\}$, where $D$ is number of problem
variables. On the contrary, when all variables are considered pairwise dependent, MP is
called compact FOS.

Before introduction of the \em MP building procedure \em it is necessary to define
\em strength of block \em $\cal S_{M}$$(\cal F$$_j)$ which determines dependency rate
within certain block $\cal F$$_j$ according to given distance measure $\cal M$. The strength of
block is defined as following:

$$
{\cal S_M}({\cal F}_i) = \cases{ {C \over D-1} \sum_{v \in {\cal I}} {\cal M}({\cal F}_i,
\{v\}) & if $|{\cal F}_i| = 1$,\cr
{1 \over |{\cal F}_i| (|{\cal F}_i|-1)} \sum_{u \in {\cal F}_i} \sum_{v \in {\cal F}_i}
{\cal M}(\{u\}, \{v\}) & otherwise,} \eqmark
$$


\noindent where $C \geq 0$ is user selected factor defining the degree of strength of 
univariete blocks.

The MP building procedures starts by initializing MP $\cal F$ as univariete FOS and by
assigning the strength of block to each block. In each step new block $\cal F$$_n$ is created
by merging two blocks ${\cal F}_a, {\cal F}_b \in \cal F$, which are determined, by given
distance measure $\cal M$, as the most dependent. Then, $\cal F$$_n$ is assigned its strength
of block. If newly created block meets the following conditions:

\begitems
\style N
*${\cal S_M}({\cal F}_n) \geq \theta_1, \theta_1 \in{\bbchar{R}}$
*${\cal S_M}({\cal F}_n) \geq K max({\cal S_M}({\cal F}_a), {\cal S_M}({\cal F}_b))$,
*$|{\cal F}_n| \leq \theta_2, \theta_2 \in{\bbchar{N}}$,
\enditems

\noindent where thresholds $\theta_1 > 0$, $\theta_2 \in [1, D]$ and  factor $K \in (0,1]$ are defined by user.
Then $\cal F$$_n$ is inserted to the FOS $\cal F$ and $\cal F$$_a, \cal F$$_b$ are 
removed from $\cal F$. The procedure runs until a newly created block $\cal F$$_n$ has not
met mentioned conditions or until MP has became the compact FOS.

The \em DE using the MP FOS structure \em (MP DE) build the MP in every generation.
After building the MP, MP DE traverses FOS in the opposite order of the merging, in
other words, from the last one added to FOS to the first one.


\midinsert \clabel[DEFOSpseudocode]{Provisional}
\picw=14cm \cinspic DEFOSpseudocode.jpg
\medskip
\caption/f provisional pseudocode
\endinsert


\label[ch4] \chap Identification of the linkage structure

In previous chapter two possible representations of dependency structure were introduced.
In order to represent the dependency structure, it is necessary to determine the degree
of dependence between each pair of variables and furthermore between each pair of sets of
variables. The tool used to measure the degree is called the distance measure and is
denoted as $\cal M$.

Formally, $\cal M$ is a function that takes two sets of variables as input and produces a
real, positive number as output. $\cal M$ is defined as follows~\cite[LT]:

$$
{\cal M}(X_i, X_j) = {1 \over |X_i| |X_j|} \sum_{u \in X_i} \sum_{v \in X_j}
p_{u, v} \eqmark
$$

\noindent where $X_i$ and $X_j$ are sets of variables and $p_{u, v}$ is element of the
\em dependency matrix \em $\cal P$ at position $u,v$.

The dependency matrix 

$$
%{\cal N} = \pmatrix{ a & b & \dot \cr c & d & \dot}
{\cal P} = \pmatrix{p_{0,0} & p_{0,1} & \dots & \dots & p_{0, D-1} \cr 
p_{1,0} & p_{1,1} & & & \vdots \cr
\vdots & & \ddots &  & \vdots \cr
\vdots & &  & \ddots & \vdots \cr
p_{D-1, 0} & \dots & \dots & \dots & p_{D-1, D-1}} \in {\bbchar R}^{D \times D}
$$

\noindent is a symetric and positive semi-definite matrix.
The dependency matrix gives the dependency between each pair of variables specifically,
the element $p_{i, j}$ denotes he pairwise dependency strength between i-th and j-th
problem variables. Consequently $\cal P$ contains zeros on diagonal i.e. $\forall i =
0, 1, ..., D-1 : p_{i, i} = 0$.

There are several methods how to contruct the dependency matrix $\cal P$ nevertheless,
this work focus only on two of them.

\sec Fitness-based method

The first method called \em non-linearity check \em (NC) is to define whether two
variables interact is directly based on fitness values. The method works under
the assumption that non-linear interactions may exist only between dependent
variables. Specially, it classify a pair of variables either separable or non-separable
by comparing the difference in overall fitness while making the exact same change for
a certain pair of chromosome of given individual $x_{i, j}$ for different values of
$x_{i, k}, k \neq j$.~\cite[LINC, LIMD] Nevertheless, checking only one individual
is not convincing enough, because there may exist linearity between a dependent pair
of variables in some context, therefore more individuals must be checked. In this work,
$m$ best individuals from the population are checked, where $m = max\{2, {3 \over 20}NP\}$.
$C$ denotes the set of indices of $m$ best individuals in population.

For each of chosen individuals $\vec{x}_i, i \in C$ and for each pair of variables $j$, $k$
a pairwise dependency $d_{i,j,k}$ is calculated. The overall pairwise dependency between
those variables is determined by aggregating those values as following:

$$
p_{j, k} = {1 \over m} \sum_{i \in C} d_{i,j,k}.
$$

In order to calculate $d_{i,j,k}$, four individuals are picked by combining all possible
points that can be created by picking two different values for each $x_{i,j}$ and
$x_{i,k}$.~\cite[MAIN] The absolute value of differences in overall fitness value
for those point are used to calculate the potential dependence between \em j-th \em and
\em k-th \em variables by determining whether the adjustment to $x_{i,k}$ affect the change
in fitness caused by modification to $x_{i,j}$. Define:

$$
\Delta_{i, j} = |(f(\vec{x}_i) | x_{i, j} = a_j, x_{i, k} = a_k) - (f(\vec{x}_{i}) |
x_{i, j} = a_j + b_j, x_{i, k} = a_k)|,
$$
$$
\Delta_{i, j,k} = |(f(\vec{x}_i) | x_{i, j} = a_j, x_{i, }k = a_k + b_k) -
(f(\vec{x}_i) | x_{i, j} = a_j + b_j, x_{i, k} = a_k + b_k)|, 
$$

\noindent where $f$ denotes fitness function, $a_j, a_k, b_j, b_k$ can be any real value,
such that for every variable $j, a_{j}$ and $a_{j} + b_{j}$ remains within the bound
for $x_{i,j}$ inside the current population, to put it more formally:

$$
\forall j :\max_{\vec{x}_i \in P}(x_{i,j}) \geq a_j \geq \min_{\vec{x}_i \in P}(x_{i,j}),
$$

$$
\forall j :\max_{\vec{x}_i \in P}(x_{i,j}) \geq a_j+b_j \geq \min_{\vec{x}_i \in P}(x_{i,j}),
$$

\noindent nevertheless, in this work are used values that have been empirically found
for~\cite[MAIN], which are

$$
a_j = \min_{\vec{x}_i \in P}(x_{i, j}) + (\max_{\vec{x}_i \in P}(x_{i, j}) -
\min_{\vec{x}_i \in P}(x_{i, j})) * 0.35,
$$

$$
b_j = (\max_{\vec{x}_i \in P}(x_{i, j}) - \min_{\vec{x}_i \in P}(x_{i, j})) * 0.35.
$$

Finally, \em j-th \em and \em k-rh \em are said to dependent when $|\Delta_{i,j} - \Delta_{i, j,k}|
\geq 0$, the pairwise dependent $d_{i,j,k}$ is defined as:

$$
d_{i,j,k} = \cases{1 - {\Delta_{i,j,k} \over \Delta_{i,j}} & if $\Delta_{i,j} \geq \Delta_{i,j,k}$,
\cr 1 - {\Delta_{i,j} \over \Delta_{i,j, k}} & otherwise.} \eqmark
$$

\noindent note that $d_{i,j,k}$ as well as $p_{j,k}$ lie within $[0, 1)$ with $0$ indicating
independent variables.


\sec Distribution-based mathod
The second method to construct the dependency matrix $\cal P$ is called the \em maximal
information coefficient \em (MIC)~\cite[MIC]. There exists more methods used to identify
dependencies between a pair of variables based on the distribution of the
population~\cite[MP, MAIN], however MIC achieved better accurancy in comparison to other
methods.~\cite[MIC, MIC2]

MIC is based on the idea, that if a relationship between a pair of variables exists,
then it is posible to draw a grid on the scatterplot of the two variables that partitions
the data to encapsulate that relationship.

To calculate MIC, all possible grids up to maximal grid resolution are considered. Note
that maximal grid resolution depends on the sample size. For each pair of integers $(x, y)$
the largest possible mutual information (MI)~\cite[MI] achieveable by any x-by-y grid applied
to the data is computed. Those mutual information values are then normalized by the logarithm
of the minimum $x$ and $y$. Finally, MIC is defined as maximum of thos highest normalized
mutual information values.~\cite[MIC] Formally:

$$
MIC_{i,j} = \max_{(x,y) : x \leq B, y \leq B} \Bigg( \max_{g : G_{x, y}} \Big( {MI_{i,j}|_g
\over \log \min(x, y)} \Big)\Bigg),
$$

\noindent where $B$ is user-specified value defining maximal grid resolution, $G_{x,y}$ denotes
a set of all possible x-by-y grids and $MI_{i,j}|_g$ stands for mutual information of $i$-th and
$j$-th variables achieved by application of grid $g$.

As was mentioned above achieved good results in various comparisons, however a big limitation
of MIC is its high computational cost. Therefore several optimized algorithms for approximating
the MIC have been published.~\cite[MIC, TIC, GMIC]. In this work MICE \em minepy \em
implementation~\cite[MICE, MINEPY] is used.

In this wrok MICE is not calculated from the whole population, but only subset $C$ of all
individuals in population is considered. The dependency matrix $\cal P$ is then formally
calculated as following:


\centerline{$p_{i,j} = $ MICE$_{i,j}|_C$.}



\label[ch5] \chap Experiments

In \ref[s23] section the standard differential evolution was introduced. It was also noted
that DE does not have any tool to recognize or model the linkage information between certain
parts of solution. In chapter \ref[ch3] two possible
representations of dependency structure were introduced assuming known pairwise dependencies
and in the chapter ~\ref[ch4] two ways to find pairwise dependencies and thereby build the dependency matrix
$\cal P$ were presented.

By combination of above it is possible to propose adjusted DE with dependency detection. The
adjusted version differs from original in two factors. Firstly, in every generation the
dependency matrix $\cal P$ and FOS structure based on it is built. Secondly, crossover is
modified to respect dependent blocks.

\midinsert \clabel[DE final]{Differential evolution with dependency detection}
\picw=14.7cm \cinspic DE_final.png
\bigskip
\caption/f Pseudocode of the differential evolution with dependency detection
\endinsert

The main goal of experiments is to study performance of various types of DE with dependency
detection differing in creating the matrix $\cal P$, or in the building FOS $\cal F$. Compare
them between each other and with standard DE and other optimization algorithms.

\label[s51] \sec Algorithms

\label[s511] \secc Differential evolution variants

Within the experiments seven types of differential evolution were compared. The original DE
as was introdued in~\ref[s23] section. (DE\_UNIFORM). Remaining six variants of DE are divided
into three pairs according to how they create the distance matrix $\cal P$. Within each pair,
one variant uses linkage tree FOS (LT) and second marginal product FOS (MP). The first pair
uses nonlinearity check to create $\cal P$ (DE\_LT\_NC and DE\_MP\_NC). The second pair take
advantage of maximal information coefficient (DE\_LT\_MIC and DE\_MP\_MIC). The third pair
are DE variants with full prior knowledge of pairwise dependencies, therefore they build
optimal $\cal P$, which is (0, 1)-matrix with zeros for independent pairs and ones for
dependent (DE\_LT+ and DE\_MP+).

\midinsert \clabel[DEvariants]{Differential evolution variants}
\ctable{cccc}{
\hfil 
& Nonlinearity check & Max. inf. coeff. & Optimal \crl \tskip4pt
Linkage tree & DE\_LT\_NC & DE\_LT\_MIC & DE\_LT+ \cr
Marginal product & DE\_MP\_NC & DE\_MP\_MIC & DE\_MP+ \cr
}
\caption/t Overview of newly proposed variants of the differential evolution.
\endinsert

\noindent All above-mentioned types shares the following:

\begitems
*Initialization of individuals $\sim {\cal N}({\bf 0},100 \cdot {\bf I}_D)$, where $\cal N$ is
multivariate normal distribution, $\bf 0$ stands for the zero vector and ${\bf I}_D$ represents
$D \times D$ identity matrix.
*The differential weight $F = 0.7$
\enditems

\noindent Other parameters:

\begitems
*The crossover probability for DE\_UNIFORM: $CR = 0.9$
*The degree of strength of univariate blocks:
$$
C = \cases{ 1 & for DE\_MP+,\cr
2 & otherwise.} 
$$
*Threshold $\theta_1$ defining the minimal strength of block to be accepted:

$$
\theta_1 = \cases{ 10^{-1} & for DE\_MP\_MIC,\cr
10^{-8} & otherwise.} 
$$
*Maximal size of block: $\theta_2 = 6$
*Maximum potential degree of strength of block reduction during merging

$$
K = \cases{ 0.8 & for DE\_MP+,\cr
0.4 & for DE\_MP\_NC,\cr
0.7 & for DE\_MP\_MIC.} 
$$

*Number of checked individuals within non-linearity check method: $m = \lceil0.15 \cdot NP\rceil$
*The subset used to calculate MICE $C = C_b \cup C_r$, where $C_b$ is set of $\lceil 0.3 \cdot
NP\rceil$ best individuals in population and $C_r$ is a set of $\lceil 0.1 \cdot NP\rceil$
randomly chosen individuals from the remaining.
*The maximal MICE grid resolution $B$ is set according to the table~\ref[T52] (rounded to the
nearest integer in an upward direction).
\midinsert \clabel[T52]{MICE grid resolution \em B \em}
\ctable{ll}{
\hfil 
Number of samples & B parameter\crl \tskip4pt
$|C| < 25$ & $ |C|^{0.85}$ \cr
$25 \leq |C| < 50$ & $|C|^{0.8}$ \cr
$50 \leq |C| < 250$ & $|C|^{0.75}$ \cr
$250 \leq |C| < 500$ & $|C|^{0.7}$ \cr
$500 \leq |C| < 1000$ & $|C|^{0.65}$ \cr
$1000 \leq |C| < 2500$ & $|C|^{0.60}$ \cr
$2500 \leq |C| < 5000$ & $|C|^{0.55}$ \cr
}
\caption/t The dependence of the cardinality of $C$ on the parameter $B$, taken
from~\cite[MICE].
\endinsert

*For the MICE parameter $c$ which determines how many more clumps
there will be than columns in every partition was set default value $15$~\cite[MICE]
\enditems


\noindent All above-mentioned values were found empirically unless otherwise stated.

\secc Other algorithms

Covariance matrix adaptation evolution strategy (CMA-ES) belongs to the class of
evolutionary algorithms. CMA-ES is considered state-of-the-art in evolutionary
computation and has very quickly become the standard tool for continuous
optimisation.~\cite[CMAES1, CMAES2, CMAES3]
In this work the Hanses's implementation of CMA-ES with default parameters is
used.~\cite[CMAESIMPLEMENTATION]

Last considered algorithm is Nelder-Mead simplex algorithm~\cite[FMIN], the optimization algorithm
which is not an evolutionary algorithm nevertheless, it uses only function values,
therefore may be used for blackbox optimization. The Scipy implementation called
FMIN is used~\cite[SCIPY]. Minimal absolute difference in candidate solution between iterations
(\em xtol \em) as well as minimal absolute difference in fitness function values between
iterations (\em ftol \em) is set to $10^{-12}$. Independent restarts are allowed.



\sec Test problems

The first set of benchmarking problems is called Test problems. Those problems are in a sence
suitable for above-introduced algorithms (unconstrained, noiseless, ...). These six
optimization problems to minimise are considered to study the impact of various types of
linkage learning on the performace of DE and to benchmark considered algorithms.

Before the introduction of the Test problems, state the important property of functions, the
\em additive separability\em. Define additively separable function $F$ as:

$$
F(x_0, x_1, ..., x_{D-1}) = f_0(x_0) + f_1(x_1) + ... + f_{D-1}(x_{D-1}),
$$

\noindent where $f_0, f_1, ..., f_{D-1}$ are functions of one variable. It is crucial that
the optimum of D-dimensional additively separable function may be obtained by performing
D independent one-dimensional optimizations along each dimension, formally:

$$
\min_{[x_0, x_1, ..., x_{D-1}] \in{\bbchar{R}^D},} F(x_0, x_0, ..., x_{D-1}) = \min_{x_0 \in{\bbchar{R}}}
f_0(x_0) + \min_{x_1 \in{\bbchar{R}}} f_1(x_1) + ... + \min_{x_{D-1} \in{\bbchar{R}}} f_{D-1}
(x_{D-1})
$$

It can be seen that standard DE which optimize each dimension independently would be suitable
for optimizing additively separable functions because additively separable function are
exactly those function without dependencies between variables.


\secc Sphere

The first benchmark function is sphere funcion also known as De Jong F1~\cite[DEJONG]. It is presumable the easiest
continous domain optimization problem. It is convex, separable and has one local minimum.

Definition of the sphere function:
$$
f_{sphere}(\vec{x}) = \sum_{i=0}^{D-1}x_i^2
$$
Global minimum:
$$
f_{sphere}(\vec{x}_{min}) = 0
$$
$$
\vec{x}_{min} = [0, 0, ..., 0]
$$


\secc Levy

The second considered benchmark problem is Levy function~\cite[LEVY]. Like Sphere, it is separable
function with one local minimum nevertheless, Levy function is considered more difficult to
optimize.

The Levy function is defined as follows:
$$
f_{Levy}(\vec{x}) = \sin^2(\pi v_0) + \sum_{i=0}^{D-2}\Big[(v_i -1)^2 (1 + 10\sin^2(\pi v_i +1)
)\Big] + (v_{D-1} - 1)^2 (1 + sin^2(2\pi v_{D-1})), 
$$
\noindent where $v_i = 1 + {x_i -1 \over 4}$, for all $i = 0, 1, ..., D-1$.
\medskip
\noindent Global minimum:
$$
f_{Levy}(\vec{x}_{min}) = 0
$$
$$
\vec{x}_{min} = [1, 1, ..., 1]
$$

\secc Rastrigin

The Rastrigin function~\cite[RASTRIGIN, RASTRIGIN2] is the third benchamrk problem. Like the previous functions, this one
is also separable. It it difficult function to optimize, due to regular ‘‘noise'' it has many
regularly distributed local minimum. The Rastrigin function is defined as:
$$
f_{Rastrigin}(\vec{x}) = 10 \cdot D + \sum_{i=0}^{D-1}\Big [x_i^2 - 10\cos(2\pi x_i) \Big]
$$
Global minimum:
$$
f_{Rastrigin}(\vec{x}_{min}) = 0
$$
$$
\vec{x}_{min} = [0, 0, ..., 0]
$$

\secc Rosenbrock
The Rosenbrock function~\cite[ROSENBROCK], also known as Banana function is the first considered unseparable
function, because it has overlapping dependencies. Each pair of consecutive variables is
dependent. The Rocenbrock function contains narrow, parabolic valley, where the global
minimum is located. However, even though this valley is easy to find, convergence to the
minimum is difficult~\cite[HARDROSENBROCK]. The definition of Rosenbrock function is as follows:
$$
f_{Rosenbrock}(\vec{x}) = \sum_{i=0}^{D-2} \Big [100 (x_{i+1} - x_i^2)^2 + (1 - x_i)^2\Big]
$$
Global minimum:
$$
f_{Rosenbrock}(\vec{x}_{min}) = 0
$$
$$
\vec{x}_{min} = [1, 1, ..., 1]
$$

\secc SoREB

The Sum of Rotated Ellipsoid Blocks or abbreviated SoREB~\cite[MP] is defined as follows:
$$
f_{Ellipsoid}(\vec{x}) = \sum_{i=0}^{l-1} \Big [10^{{6i \over l-1}}x_i^2\Big]
$$
$$
f_{SoREB}(\vec{x}, k) = \sum_{i=0}^{D/k-1} \Big[f_{Ellipsoid}\big(R_\theta([x_{ki}, ..., x_{k(i+1)-1}])\big) \Big]
$$

\noindent Where $R_\theta$ defines the rotation of a vector around the origin by the angle of
$\theta$ and $k$ is size of block, defined by user. Rotated blocks of variables which enter to
$f_{ellipsoid}$ as an input creates strongly connected components. Variables within the block
have strong dependencies but are completely independent of any variables outside their block.
This feature is called block-separability.

Within comparison four types of the SoREB function differing in the size of blocks (2, 3, 4, 5)
were considered. The rotation of $\theta = {\pi / 8}$ was used with one exception, if $D = 5$, 
$k$ is set to 4.

\noindent Global minimum:
$$
f_{SoREB}(\vec{x}_{min}, k) = 0; k \in{\bbchar{N}}
$$
$$
\vec{x}_{min} = [0, 0, ..., 0]
$$



\secc OSoreb

The SoREB function conations only non-overlapping non-decomposable block of size $k$. In~\cite[MP]
the overlapping version of this problem was defined as OSoREB. In addition to the original
SoREB problem a SoREB blocks of length 2 for every pair of successive variables in belonging to
other original blocks are used. For OSoREB is used $k = 5$ and $\theta = \pi / 8$.
Definition of OSoREB:
$$
f_{OSoREB}(\vec{x}, k) = f_{SoREB}(\vec{x}, k) + \sum_{i=1}^{D/k-1} \Big [f_{Ellipsoid}\big(R_\theta([x_{ki-1}, x_{ki}])\big)\Big]
$$
Global minimum:
$$
f_{OSoREB}(\vec{x}_{min}, k) = 0; k \in{\bbchar{N}}
$$
$$
\vec{x}_{min} = [0, 0, ..., 0]
$$


\sec Black Box Optimization Benchmarking problems

Black Box Optimization Benchmarking (BBOB) problems is the second consedered set of
benchmarking problems. It is a set of 24 noise-less real-parameter single-objective benchmark
functions defined in ~\cite[BBOBFUNC] as Real-Parameter Black-Box Optimization Benchmarking
2009 Noiseless Functions. Those function were used for BBOB workshop 2009.
The BBOB problems were selected with intention to evaluate the performance of algorithms
with regard to standard difficulties which occurs in continuous domain search. So they
definitely should, at least to a certain extent, reflect problems that are dealt with in
practice. All BBOB problems are to be minimised.

It is important to note that since BBOB problems cover wide range of possible optimization
problems, proposed DE variants may be unsuitable for some of them. For instance, proposed
DE variants lack a tool to handle constrains. 




\sec Setup

All experimental results described in this work~\ref[ch6] measures the first time a global
optimum was hit, in other words, the number of fitness function calls needed to reach the
small enough neigbourhood of the global optimum for the first time within the run.
The toleration is $10^{-8}$.

\secc Test problems specifics

For each problem, each algorithm and each dimension 25
independent runs are performed. The performance is considered successful if at least 24 runs
converged to the global optimum or to a predefined sufficiently close approximation within
$300000 \cdot D$ calls of the fitness function. 

The associate population size of evolutionary algorithms is the smallest possible size so that
the algorithms performance is considered successful. It is determined by starting from
smallest possible population and letting the algorithm runs 25 times. If the performance 
have not been successful, the population size for the next trial will increase by $k$. This
procudere is repeated until the successful population size is found ot until population size
reaches upper limit $T$. In the first case optimal population size is searched for by
performing bisection search between the current poopulation size and the previous size. In
the second case is considered unsuccessful for certain problem and dimension.

\secc BBOB problems specifics

The setup for BBOB problems is partially determined by authors of BBOB problems in \cite[BBOBSETUP].
For each algorithm, dimension and optimized function five different function \em instances \em
are used, each of them three times. The number of fitness functon calls is limited to
$1000000 \cdot D$. The population size is set to 25, except for algorithms using MIC, for which
it is increased to 50. For BBOB problems algorithm DE\_LT+ and DE\_MP+ are not considered,
because the dependency structure of the problems may be unclear.

BBOB problems evaluation as well as results visualization is provided by COCO (COmparing
Continuous Optimizers) platform~\cite[COCO].


\label[ch6] \chap Results

In this chapter the results of experiments introduced in previous chapter \ref[ch5] are
presented. The results are divided into two sections.


\label[s61] \sec Test problems
Firstly, results of the performance of the algorithms introduced in section \ref[s51] on the
Test problems. Results are visualized in the form of graphs, which shows the dependence of
the number of fitness function calls on the dimension of certain problem. These graphs are
called scalability graphs. They shows the most important facets of algorithm's performance
whatsmore, they provides a prediction regarding the performance on higher-dimensional problems.

Each data point is the median of successful runs.
To display data over a very wide range of values in a compact way and to get clearer results,
a base-10 logarithmic scale is used for both axis of graphs. It is also worth noting that the
y-axis does not start at zero.

The Test results may be divided into three groups according to separability into separable
problems (sphere, Levy, Rastrigin), block-separable problems (SoREB) and non-separable
problems (Rosenbrock, OSoREB).
\medskip
\noindent 1) Separable problems
\medskip

For all three separable problems both algorithms with full prior knowledge (DE\_LT+, DE\_MP+)
perform very similarly. For the easiest function (sphere) is DE\_LT+ a bit better,
nevertheless for more difficult problems, the DE\_MP+ achieves
a little better results than DE\_LT+ (for Levy and Rastrigin).

Since separable problems does not conatin any dependencies between variables, it is not
surprising that there is almost no difference in performance of DE\_LT\_MIC and DE\_LT+,
because for separable problems, all possible linkage trees should be equally good. Therefore
is does not matter what dependency matrix $\cal P$ DE\_LT\_MIC find and subsequently what
linkage tree it build, the linkage tree would be just as good as the one built by DE\_LT+.

The DE\_MP\_MIC is slightly worse than DE\_LT+, DE\_MP+ and DE\_LT\_MIC especially for higher
dimensions. It is very hard to recognize separability by MIC because the DE selection
operator alignt individuals with the fitness contours. Therefore DE\_MP\_MIC may determine
some variables as dependent and build suboptimal MP-FOS which results in worse performace

Although both algorithms usign non-linearity check (DE\_LT\_NC, DE\_MP\_NC) correctly
recognize the separability of the problem and build optimal FOS, they have achieved significantly
worse results than other newly-introduced variants of DE. The difference is mainly caused by the
fact that DE\_LT\_NC and DE\_MP\_NC uses fitness function evaluations to find dependencies, in
contrast with DE\_LT+, DE\_MP+ and DE\_LT\_MIC which also build optimal FOS but do not waste
fitness function evaluations.

It also provides an explanation of why the DE\_LT\_NC outperforms DE\_MP\_NC. Since
DE\_LT\_NC, DE\_MP\_NC build optimal FOS, the DE\_LT\_NC performes comparably to DE\_LT+
within crossover. Similarly to DE\_MP\_NC and DE\_MP+. And since DE\_LT+ and DE\_MP+
perform similarly, DE\_LT\_NC and DE\_MP\_NC use comparable number of fitness function
evaluations within the crossover. It is a fact that LT-FOS has necessarily higher
cardinality than MP-FOS for same dimension, therefore DE\_LT\_NC find the optimimum
within less number of generations than DE\_MP\_NC. Since dependency matrix is built
in each generation, DE\_MP\_NC uses more fitness function calls to find dependencies
which results in worse performance then DE\_LT\_NC.

CMA-ES has achieved interesting results. For the sphere function, CMA-ES is a constant factor
better than DE\_LT+, DE\_MP+, DE\_LT\_MIC, DE\_MP\_MIC, nevertheless as the difficulty of
optimization of functions grows, the performance of CMA-ES is getting worse. For Levy function
CMA-ES perform similarly to four mention algorithms and for the hardest function (Rastrigin)
CMA-ES is significantly worse and achieves results comparable to DE\_LT\_NC and DE\_MP\_NC.
But it is worth notting that CMA-ES scales better than NC variants of DE.

Finally, FMIN outperforms all algorithms for low dimensions of sphere, nevertheless scales
very bad and get outperformed by all algorithms in higher dimensions. FMIN is unable to find
optimum, even for low dimensions, of harder functions as Levy and Rastrigin.

\midinsert \clabel[separable]{Separable problems graphs}
\picw=14.3cm \cinspic separable.png
\caption/f Scalability graphs of separable problems. Each point is the median of
successful runs.
\endinsert

\medskip
\noindent 2) Block-separable problems
\medskip

The separable problems are represented by SoREB function with variable size of block (2, 3, 4
, 5). It is worth notting the relationship between particular pair of DE variants which use
same technique build dependency matrix.

Firsty, the DE\_MP+ is, a constant factor better than DE\_LT+. It is not surprising, since
block-separable structure of a problem may be represented by MP FOS very well.

However for the second pair, which uses non-linear check, it can be seen that LT variant
(DE\_LT\_NC) outperforms MP variant (DE\_MP\_NC). Although DE\_MP\_NC build same FOS as
DE\_MP+, which perfcetly capture the structure of the problem, it cannot achieve better
results than DE\_LT\_NC. It points to the fact that, worse performance within the crossover
is compensated by lower number of fitness function evaluations used to find dependencies.

Lastly, MIC variants (DE\_LT\_MIC, DE\_MP\_MIC) perform almost similarly for block size two
and three. For $k = 4$ and $k = 5$ DE\_LT\_MIC achieve better result than DE\_MP\_MIC,
nevertheless for the higher dimensions dependent blocks the dependent blocks are easier to
recognize and the DE\_MP\_MIC outperforms DE\_LT\_MIC.

The relationship between MIC variants and NC variants is also worth notting. It can be seen
that, for $k = 2$ both MIC variants perform similarly to DE\_LT+ and better than NC variants,
however as the size of block increases and more dependencies occur, MIC variants are getting
outperformed by NC variants. It is causes by weaker ability of MIC to recognition dependencies,
especially for low number of samples.

The original DE\_UNIFORM performace shows up as the worst of all considered algorithms for
block-separable problems. For bigger sizes of blocks the DE\_UNIFORM is even worse.

CMA-ES perform similarly for all sizes of blocks in terms of the required number of evaluations.
Since other algorithms need more evaluations for bigger blocks, CMA-ES outperforms all algorithm
except DE\_MP+ for $k = 5$. Nevertheless DE\_LT+ and DE\_MP+ outscale CMA-ES, which scalability
is comparable to DE\_LT\_NC and DE\_MP\_NC.

Last considered algorithm FMIN shows best performace for small dimension, but the worst
scalability of all algorithm and inability to find optimum for higher dimensions.

Lastly note that DE\_LT+ and DE\_LT\_NC need on average more evaluations to find optimum for
$D = 5$ than for $D = 5$ if $k = 5$, which shows certain limitations of LT when al variables
are pairwise dependent.

\midinsert \clabel[BLOCKSEPARABLE]{Block-separable problems graphs}
\picw=14.3cm \cinspic block-separable.png
\bigskip
\caption/f Scalability graphs of block-separable problems. Each point is the median of
successful runs.
\endinsert

\medskip
\noindent 3) Non-separable problems
\medskip

Firstly, it is worth notting that no DE variant which build MP-FOS is able to find optimum
of presented non-separable problems, even for small dimension. It is probably caused by
overlapping dependency structure of both problems, which is impossible to model by MP-FOS.

DE\_LT+ and DE\_LT\_MIC perform almost identicaly, the same trend may be observed in figure
\ref[separable] representing results on separable functions. For Rosenbrock DE\_LT+ and
DE\_LT\_MIC scale better than DE\_LT\_NC, nevertheless for OSoREB DE\_LT+ and DE\_LT\_MIC
are only a constant factor better than DE\_LT\_NC. The slightly better relative scalability
towards DE\_LT+ and DE\_LT\_MIC corresponds to the results obtained in \ref[block-separable]
because OSoREB is in a sense closer to the block-separable problem than Rosenbrock and the
dependency structure of OSoREB may be captured better within LT-FOS than the structure of
Rosenbrock. Therefore the impact of correct recognition of dependencies, which DE\_LT\_NC
does, increases.

The same phenomenon may be seen in performance of DE\_UNIFORM which is a constant better than
DE\_LT\_NC for Rosenbrock, with relative small number of dependencies. Nevertheless as the 
number of dependencies increase from Rosenbrock to OSoREB, the scalability of DE\_UNIFORM
is getting worse and DE\_UNIFORM is unable to find optimum of OSoREB in higher dimensions.

On the other hand, the opposite trend can be viewed on performance of CMA-ES, which
outperforms all other algorithms nevertheless, for Rosenbrock the difference is less
significant and DE\_LT+ and DE\_LT\_MIC seemed to scale better than CMA-ES.

For non-separable problems, similarly as for other
FMIN show up as the best algorithm for low dimansions, similarly to sphere function, but
scale the worst. Therefore is almost useless for higher dimensions.


\midinsert \clabel[NonSEPARABLE]{Non-separable problems graphs}
\picw=14.3cm \cinspic non-separable.png
\bigskip
\caption/f Scalability graphs of non-separable problems. Each point is the median of
successful runs.
\endinsert


\sec BBOB problems


Results on the BBOB problems are presented by graphs of Empirical cumulative distribution
functions (ECDFs)~\cite[ECDF]. These ECDFs show on the y-axis the proportion of cases for which
the number of fitness function evaluations needed to find the optimum was smaller than the value
given on the x-axis. For x-axis a base-10 logarithmic scale is used and the total number of
fitness function evaluations is diveded by dimension. Each graph also shows performance of the
best algorithm of BBOB workshop 2009 noted as \em best 2009 \em.

All results in this section were obtained by COCO platform. Complete results contains
25 function for various dimensions (2, 3, 5, 10, 20, 40). Complete results are shown in
Appendix~\ref[APPA].
In this section, only selected functions of dimensions 5 and 20 occurs. 
These functions were chosen to represent characteristic trend seen for more functions.

Firstly, the set of functions on which all DE variants perform similarly but worse than CMA-ES
and best 2009.
This set is represented by so called Ellipsoid separable function on figure 6.4.

\midinsert \clabel[ELLIPSOIDSEP]{Ellipsoid separable function graphs}
\picw=.4\hsize
\centerline {\inspic Ellipsoid5.png \hfil\hfil \inspic Ellipsoid20.png }\nobreak
\medskip
\caption/f Graphs of the empirical cumulative distribution functions of the introduced algorithms
on the Ellipsoid separable function for dimensions five and twenty.
\endinsert

Secondly, for a number of functions, MP varints of DE are outperform by other DE variants,
especially for higher dimensions, nevertheless LT and UNIFORM variants are outperformed by
CMA-ES and by best 2009. The example of such a function may be seen on figure 6.5.

\midinsert \clabel[BENT]{Bent function graphs}
\picw=.4\hsize
\centerline {\inspic Bent5.png \hfil\hfil \inspic Bent20.png }\nobreak
\medskip
\caption/f Graphs of the empirical cumulative distribution functions of the introduced algorithms
on the Bent function for dimensions five and twenty.
\endinsert

The third observed trend within BBOB functions is significantly worse performace of DE
variants againts CMA-ES and best 2009. All DE variants are unable to find global optimum
for majority of these functions. Note that these are functions are mainly Multi-modal
functions with weak global structure. This trend is caprured on figure 6.6.

\midinsert \clabel[GRIEWANK]{Griewank function graphs}
\picw=.4\hsize
\centerline {\inspic Griewank5.png \hfil\hfil \inspic Griewank20.png }\nobreak
\medskip
\caption/f Graphs of the empirical cumulative distribution functions of the introduced algorithms
on the Ellipsoid separable function for dimensions five and twenty.
\endinsert


\chap Conclusion

The main goal of this work was to propose a crossover operatior with dependency detection
for DE.

In chapter~\ref[ch3] were introduced two representations of the dependency structure, linkage
tree (LT) which contains itself multiple levels of dependencies, from univariate level to
complete dependency, and marginal product (MP) which contains every problem variable exactly once.

In chapter~\ref[ch4] two approaches that can find pairwise dependencies between variables were
introduced. First, fitness-based approach called non-linearity check (NC) determining the
possible dependence between a pair of variables according to the fitnes values. Second approach
called maximal information coefficient (MIC) indentifies dependencies based on the 
distribution of the population.

Subsequently six new variants of DE differing in the crossover operator were proposed in 
section~\ref[s51]. Except four regular variants using above-mention methods
DE\_LT\_NC, DE\_MP\_NC, DE\_LT\_MIC, DE\_MP\_MIC, two artifical variants with full prior
knowledge of dependency structure were also proposed. 

According to results presented in section ~\ref[s61], newly proposed methods show to achieve a
fair scalability, all of them outscale the original DE (DE\_UNIFORM) for almost all test
problems, independent of the dependency structure. They also showed better scalability than
FMIN algorithm and for some problems even better scalability than state-of-the-art
evolutionary algorithm CMA-ES. So usege any of four propsoed regular variants of DE instead
of original one would bring better performace.

According to the results from previous chapter it may be concluded that linkage tree
representation, thanks to its robustness, is seemed to be better choice than marginal
product representation.

It is worth noting that the results obtained by our NC methods should be compared to
the MIC results with careful consideration. For instance, while NC methods can easy recognize
separability of two variables, for MIC ones the same task is very hard because the DE selection
operator alignt individuals with the fitness contours. On the other hand, MIC variants, in
contrast with NC ones, do not need any fitness function evaluations to find dependencies.
The disadvantage of MIC is that DE usually take advantage of relative small populations and
since MIC is a statistical method, it achieves better results with more samples. On the other
hand MIC would probably be more noise resistant than NC. However, no experiments to
substantiate this assumption have not been presented so far, so there is a space for future
work to prove or refute this hypothesis.

Although all four regular variants of DE enhance the performance of the original DE,
they have some limitations which would be be reduced by further adjustments.

For instance, \em incremental dependency updating \em described in~\cite[MAIN] would
propably significantly reduce the amounth of fitness function evaluations used by NC methods
to find dependencies and decrease the difference in performance between NC methods
and methods with full prior knowledge.

The last unaswered question is, how to deal with problems containing overlapping
sub-components. Not LT nor MP are able to represent these types of structures very
well, whatsmore the optimal linkage structure of these problems is unknown. So to
find the optimal structure for these problems would be also very interesting.

\bibchap
\usebib/c (simple) myreferences

\label[APPA]  \app Complete BBOB results

\bye